{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing and Plotting Results\n",
    "\n",
    "## Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.io.formats.style\n",
    "\n",
    "from repsim.benchmark.paths import BASE_PATH\n",
    "from IPython.display import display\n",
    "\n",
    "measure_to_abbrv = {\n",
    "    \"AlignedCosineSimilarity\": \"AlignCos\",\n",
    "    \"CKA\": \"CKA\",\n",
    "    \"ConcentricityDifference\": \"ConcDiff\",\n",
    "    \"DistanceCorrelation\": \"DistCorr\",\n",
    "    \"EigenspaceOverlapScore\": \"EOS\",\n",
    "    \"GeometryScore\": \"GS\",\n",
    "    \"Gulp\": \"GULP\",\n",
    "    \"HardCorrelationMatch\": \"HardCorr\",\n",
    "    \"IMDScore\": \"IMD\",\n",
    "    \"JaccardSimilarity\": \"Jaccard\",\n",
    "    \"LinearRegression\": \"LinReg\",\n",
    "    \"MagnitudeDifference\": \"MagDiff\",\n",
    "    \"OrthogonalAngularShapeMetricCentered\": \"AngShape\",\n",
    "    \"OrthogonalProcrustesCenteredAndNormalized\": \"OrthProc\",\n",
    "    \"PWCCA\": \"PWCCA\",\n",
    "    \"PermutationProcrustes\": \"PermProc\",\n",
    "    \"ProcrustesSizeAndShapeDistance\": \"ProcDist\",\n",
    "    \"RSA\": \"RSA\",\n",
    "    \"RSMNormDifference\": \"RSMDiff\",\n",
    "    \"RankSimilarity\": \"RankSim\",\n",
    "    \"SVCCA\": \"SVCCA\",\n",
    "    \"SecondOrderCosineSimilarity\": \"2nd-Cos\",\n",
    "    \"SoftCorrelationMatch\": \"SoftCorr\",\n",
    "    \"UniformityDifference\": \"UnifDiff\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "nlp_root = BASE_PATH /\"paper_results\" / \"nlp\"\n",
    "for path in nlp_root.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    setting = path.name.split(\"_\")[0]\n",
    "\n",
    "    pattern = r'(?<=_)sst2(?=_)|(?<=_)mnli(?=_)'\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "nlp_data = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "root = BASE_PATH /\"paper_results\" /\"graph\"\n",
    "for path in root.glob(\"*.csv\"):\n",
    "    if path.name.endswith(\"backup.csv\"):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    pattern = r\"augmentation|label_test|layer_test|output_correlation|shortcut\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    pattern_to_setting = {\n",
    "        \"augmentation\": \"aug\",\n",
    "        \"label_test\": \"mem\",\n",
    "        \"layer_test\": \"mono\",\n",
    "        \"output_correlation\": \"correlation\",\n",
    "        \"shortcut\": \"sc\",\n",
    "    }\n",
    "    setting = pattern_to_setting[match.group(0)]\n",
    "\n",
    "    pattern = r\"(?<=_)cora(?=_)|(?<=_)flickr(?=_)|(?<=_)ogbn-arxiv(?=_)\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "graph_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data[(graph_data.representation_dataset==\"cora\") & (graph_data.Setting == \"correlation\") & (graph_data.quality_measure == \"spearmanr\")].groupby([\"architecture\", \"functional_similarity_measure\",\"similarity_measure\"]).count()\n",
    "graph_data[(graph_data.representation_dataset==\"cora\") & (graph_data.Setting == \"correlation\") & (graph_data.quality_measure == \"spearmanr\") & (graph_data.similarity_measure == \"AlignedCosineSimilarity\") & (graph_data.architecture == \"GCN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "root = BASE_PATH /\"paper_results\" /\"vision\"\n",
    "for path in root.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    pattern = r\"aug|mem|mono|correlation|sc\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    pattern_to_setting = {\n",
    "        \"aug\": \"aug\",\n",
    "        \"mem\": \"mem\",\n",
    "        \"mono\": \"mono\",\n",
    "        \"correlation\": \"correlation\",\n",
    "        \"sc\": \"sc\",\n",
    "    }\n",
    "    setting = pattern_to_setting[match.group(0)]\n",
    "\n",
    "    pattern = r\"(?<=_)in100(?=_)\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "vision_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Combine data\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "data = pd.concat([nlp_data, graph_data, vision_data])\n",
    "print(data.columns)\n",
    "\n",
    "\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"functional_similarity_measure\": \"Functional Similarity Measure\",\n",
    "        \"similarity_measure\": \"Representational Similarity Measure\",\n",
    "        \"quality_measure\": \"Quality Measure\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Copy values from correlation experiment into same column for results scores like other experiments\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"value\"] = data.loc[idx, \"corr\"]\n",
    "\n",
    "# Exclude evaluation in output correlation experiments with Kendalltau und pearsonr. We only show Spearmanr\n",
    "idx = (data.Setting == \"correlation\") & (data[\"Quality Measure\"] != \"spearmanr\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "# Update the setting to be able to distinguish correlation results with different functional similarity measures easily\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"Setting\"] = data.loc[idx, \"Setting\"] + data.loc[idx, \"Functional Similarity Measure\"]\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Clean up names etc.\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def beautify_df(data):\n",
    "    data.loc[:, \"Representational Similarity Measure\"] = data[\"Representational Similarity Measure\"].map(\n",
    "        measure_to_abbrv\n",
    "    )\n",
    "    data.loc[:, \"architecture\"] = data[\"architecture\"].map(\n",
    "        {\n",
    "            \"BERT-L\": \"BERT\",\n",
    "            \"GCN\": \"GCN\",\n",
    "            \"GAT\": \"GAT\",\n",
    "            \"GraphSAGE\": \"SAGE\",\n",
    "            \"PGNN\": \"PGNN\",\n",
    "            \"VGG11\": \"VGG11\",\n",
    "            \"VGG19\": \"VGG19\",\n",
    "            \"ResNet18\": \"RNet18\",\n",
    "            \"ResNet34\": \"RNet34\",\n",
    "            \"ResNet101\": \"RNet101\",\n",
    "            \"ViT_B32\": \"ViT B32\",\n",
    "            \"ViT_L32\": \"ViT L32\",\n",
    "        }\n",
    "    )\n",
    "    data.loc[:, \"domain\"] = data[\"domain\"].map({\"NLP\": \"Text\", \"GRAPHS\": \"Graph\", \"VISION\": \"Vision\"})\n",
    "    data.loc[:, \"Dataset\"] = data[\"Dataset\"].map(\n",
    "        {\n",
    "            \"mnli_aug_rate0\": \"MNLI\",\n",
    "            \"mnli_mem_rate0\": \"MNLI\",\n",
    "            \"mnli\": \"MNLI\",\n",
    "            \"sst2_sc_rate0558\": \"SST2\",\n",
    "            \"sst2_mem_rate0\": \"SST2\",\n",
    "            \"mnli_sc_rate0354\": \"MNLI\",\n",
    "            \"sst2_aug_rate0\": \"SST2\",\n",
    "            \"sst2\": \"SST2\",\n",
    "            \"flickr\": \"Flickr\",\n",
    "            \"ogbn-arxiv\": \"OGBN-Arxiv\",\n",
    "            \"cora\": \"Cora\",\n",
    "            \"in100\": \"IN100\",\n",
    "        }\n",
    "    )\n",
    "    data.loc[:, \"Setting\"] = data[\"Setting\"].map(\n",
    "        {\n",
    "            \"aug\": \"Augmentation\",\n",
    "            \"mem\": \"Random Labels\",\n",
    "            \"correlationJSD\": \"JSD Corr.\",\n",
    "            \"correlationAbsoluteAccDiff\": \"Acc. Corr.\",\n",
    "            \"correlationDisagreement\": \"Disagr. Corr.\",\n",
    "            \"mono\": \"Layer Mono.\",\n",
    "            \"sc\": \"Shortcuts\",\n",
    "        }\n",
    "    )\n",
    "    column_order = [\"Acc. Corr.\", \"JSD Corr.\", \"Disagr. Corr.\", \"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]\n",
    "    data.loc[:, \"Setting\"] = pd.Categorical(\n",
    "        data[\"Setting\"],\n",
    "        categories=column_order,\n",
    "        ordered=True,\n",
    "    )\n",
    "    data.loc[:, \"Quality Measure\"] = data[\"Quality Measure\"].map(\n",
    "        {\"violation_rate\": \"Conformity Rate\", \"AUPRC\": \"AUPRC\", \"spearmanr\": \"Spearman\", \"correlation\": \"Spearman\"}\n",
    "    )\n",
    "    data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"] = (\n",
    "        1 - data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"]\n",
    "    )  # must be run in conjunction with the above renaming\n",
    "\n",
    "    data = data.rename(\n",
    "        columns={\n",
    "            \"domain\": \"Modality\",\n",
    "            \"architecture\": \"Arch.\",\n",
    "            \"Representational Similarity Measure\": \"Sim Meas.\",\n",
    "            \"Quality Measure\": \"Eval.\",\n",
    "            \"Setting\": \"Test\",\n",
    "        }\n",
    "    )\n",
    "    data.loc[data.Test.isin([\"Acc. Corr.\", \"JSD Corr.\", \"Disagr. Corr.\"]), \"Type\"] = \"Grounding by Prediction\"\n",
    "    data.loc[data.Test.isin([\"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]), \"Type\"] = (\n",
    "        \"Grounding by Design\"\n",
    "    )\n",
    "    return data, column_order\n",
    "\n",
    "\n",
    "data, column_order = beautify_df(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pval_str(pval):\n",
    "    if isinstance(pval, float):\n",
    "        if pval <= 0.01:\n",
    "            return r\"$^{**}$\"\n",
    "        if pval <= 0.05:\n",
    "            return r\"$^{*\\phantom{*}}$\"\n",
    "    return r\"$^{\\phantom{**}}$\"\n",
    "\n",
    "def floatify(s: str) -> str:\n",
    "    r\"\"\"Turn a string like '-0.10$^{\\phantom{**}}$' into '-0.10'\"\"\"\n",
    "    return s[:s.find(\"$\")]\n",
    "\n",
    "def separate_significance_indicator(s: str) -> str:\n",
    "    r\"\"\"Turn a string like '-0.10$^{\\phantom{**}}$' into '$^{\\phantom{**}}$'\"\"\"\n",
    "    return s[s.find(\"$\"):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select language results\n",
    "datasets = [\"MNLI\", \"SST2\"]\n",
    "archs = [\"BERT\"]\n",
    "idx = data[\"Dataset\"].isin(datasets) & data[\"Arch.\"].isin(archs)\n",
    "tests_with_pvals = [\"Acc. Corr.\", \"JSD Corr.\", \"Disagr. Corr.\"]\n",
    "\n",
    "\n",
    "# Create pivot table\n",
    "pivot = pd.pivot_table(\n",
    "    data.loc[idx],  # type: ignore\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=\"value\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=\"Sim Meas.\")\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Test\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "display(pivot.head())\n",
    "\n",
    "# Turn values into strings for manipulation with significance markers\n",
    "unpivot = pivot.unstack().reset_index()  # values will be in col \"0\"\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].astype(\"str\")\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].apply(lambda x: f\"{round(x, 2):.2f}\")\n",
    "pivot = unpivot.pivot(index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=1,)\n",
    "unpivot\n",
    "display(pivot.head(3))\n",
    "\n",
    "# Highlight the best values by bolding\n",
    "for column in pivot.columns:\n",
    "    col = pivot.loc[:, column].astype(\"float\")\n",
    "    idx = col == col.max()\n",
    "    pivot.loc[idx, column] = pivot.loc[idx, column].apply(lambda s: r\"\\textbf{\" + s + \"}\")\n",
    "display(pivot.head(3))\n",
    "\n",
    "\n",
    "# Add significance markers\n",
    "# 1) select data that should get markers\n",
    "idx = data[\"Dataset\"].isin(datasets) & data[\"Arch.\"].isin(archs) & data.Test.isin(tests_with_pvals)\n",
    "data_corr = data.loc[idx].copy()\n",
    "\n",
    "# 2) Create new column with value and marker\n",
    "data_corr[\"val_comb\"] = data_corr[\"value\"].apply(lambda x: f\"{round(x, ndigits=2):.2f}\") + data_corr[\"pval\"].apply(pval_str)\n",
    "display(data_corr.head(3))\n",
    "\n",
    "# 3) Create pivot table for values with markers that can be inserted into the main pivot table\n",
    "pivot_corr = data_corr.pivot(\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=[\"val_comb\"],\n",
    ").sort_values(\n",
    "    by=\"Sim Meas.\"\n",
    ").reindex(\n",
    "    column_order, axis=\"columns\", level=\"Test\"\n",
    ").loc[:, \"val_comb\"]\n",
    "display(pivot_corr.head())\n",
    "\n",
    "# 4) Highlight the best scores by bolding\n",
    "for column in pivot_corr.columns:\n",
    "    col = pivot_corr.loc[:, column].apply(floatify).astype(\"float\")\n",
    "    identifiers = pivot_corr.loc[:, column].apply(separate_significance_indicator)\n",
    "    idx = col == col.max()\n",
    "    new_col = col.apply(lambda x: f\"{x:.2f}\").apply(lambda s: r\"\\textbf{\" + s + \"}\") + identifiers\n",
    "    pivot_corr.loc[idx, column] = new_col\n",
    "\n",
    "\n",
    "# Insert into main pivot\n",
    "pivot.loc[:, (\"Grounding by Prediction\")] = pivot_corr\n",
    "display(pivot.head())\n",
    "\n",
    "\n",
    "# Convert into latex file\n",
    "styled = pd.io.formats.style.Styler(\n",
    "    pivot,\n",
    "    precision=2,\n",
    ")\n",
    "\n",
    "latex_str = styled.to_latex(\n",
    "    hrules=True,\n",
    "    position=\"h\",\n",
    "    label=\"tab:nlp_results\",\n",
    "    caption=r\"\\emph{Results of Test 1-6 for the language domain}. In all cases, we use BERT models.\",\n",
    "    column_format=\"l||rr|rr|rr||rr|rr|rr|rr|rr|rr|rr|rr\"\n",
    ")\n",
    "# print(latex_str)\n",
    "\n",
    "# ----- Manual modifications --------\n",
    "lines = latex_str.split(\"\\n\")\n",
    "\n",
    "# Add opening of resizebox\n",
    "lines = lines[:3] + [r\"\\resizebox{\\linewidth}{!}{\"] + lines[3:]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Center headers\n",
    "pattern = r\"\\{r\\}\"\n",
    "replacement = r\"{c}\"\n",
    "lines = [re.sub(pattern, replacement, line) if i in [6, 7, 8, 9] else line for i, line in enumerate(lines)]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove measure row\n",
    "lines.pop(12)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove modality row\n",
    "lines.pop(9)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove Arch. row\n",
    "lines.pop(10)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "\n",
    "# Make every second row gray\n",
    "first_row_with_gray = 11\n",
    "final_rows_to_exclude = 4\n",
    "lines = [\n",
    "    r\"\\rowcolor{Gray}\" + line if i >= first_row_with_gray and (i - first_row_with_gray) % 2 == 0 else line for i, line in enumerate(lines[:-final_rows_to_exclude])\n",
    "] + lines[-final_rows_to_exclude:]\n",
    "\n",
    "# Add closing of resizebox\n",
    "lines = lines[:-2] + [r\"}\"] + lines[-2:]\n",
    "\n",
    "#\n",
    "latex_str = \"\\n\".join(lines)\n",
    "print(latex_str)\n",
    "\n",
    "with open(\"tables/nlp_everything.tex\", \"w\") as f:\n",
    "    f.write(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select language results\n",
    "datasets = [\"IN100\"]\n",
    "archs = [\"RNet18\", \"RNet34\", \"RNet101\", \"VGG11\", \"VGG19\", \"ViT B32\", \"ViT L32\"]\n",
    "idx = data[\"Dataset\"].isin(datasets) & data[\"Arch.\"].isin(archs)\n",
    "tests_with_pvals = [\"Acc. Corr.\", \"JSD Corr.\", \"Disagr. Corr.\"]\n",
    "\n",
    "\n",
    "# Create pivot table\n",
    "pivot = pd.pivot_table(\n",
    "    data.loc[idx],  # type: ignore\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=\"value\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=\"Sim Meas.\")\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Test\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "display(pivot.head(3))\n",
    "\n",
    "# Turn values into strings for manipulation with significance markers\n",
    "unpivot = pivot.unstack().reset_index()  # values will be in col \"0\"\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].astype(\"str\")\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].apply(lambda x: f\"{round(x, 2):.2f}\")\n",
    "pivot = unpivot.pivot(\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=1,\n",
    ")\n",
    "unpivot\n",
    "display(pivot.head(3))\n",
    "\n",
    "# Highlight the best values by bolding\n",
    "for column in pivot.columns:\n",
    "    col = pivot.loc[:, column].astype(\"float\")\n",
    "    idx = col == col.max()\n",
    "    pivot.loc[idx, column] = pivot.loc[idx, column].apply(lambda s: r\"\\textbf{\" + s + \"}\")\n",
    "display(pivot.head(3))\n",
    "\n",
    "\n",
    "# Add significance markers\n",
    "# 1) select data that should get markers\n",
    "idx = data[\"Dataset\"].isin(datasets) & data[\"Arch.\"].isin(archs) & data.Test.isin(tests_with_pvals)\n",
    "data_corr = data.loc[idx].copy()\n",
    "\n",
    "# 2) Create new column with value and marker\n",
    "data_corr[\"val_comb\"] = data_corr[\"value\"].apply(lambda x: f\"{round(x, ndigits=2):.2f}\") + data_corr[\"pval\"].apply(\n",
    "    pval_str\n",
    ")\n",
    "display(data_corr.head(3))\n",
    "\n",
    "# 3) Create pivot table for values with markers that can be inserted into the main pivot table\n",
    "pivot_corr = (\n",
    "    data_corr.pivot(\n",
    "        index=\"Sim Meas.\",\n",
    "        columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "        values=[\"val_comb\"],\n",
    "    )\n",
    "    .sort_values(by=\"Sim Meas.\")\n",
    "    .reindex(column_order, axis=\"columns\", level=\"Test\")\n",
    "    .loc[:, \"val_comb\"]\n",
    ")\n",
    "display(pivot_corr.head())\n",
    "\n",
    "# 4) Highlight the best scores by bolding\n",
    "for column in pivot_corr.columns:\n",
    "    col = pivot_corr.loc[:, column].apply(floatify).astype(\"float\")\n",
    "    identifiers = pivot_corr.loc[:, column].apply(separate_significance_indicator)\n",
    "    idx = col == col.max()\n",
    "    new_col = col.apply(lambda x: f\"{x:.2f}\").apply(lambda s: r\"\\textbf{\" + s + \"}\") + identifiers\n",
    "    pivot_corr.loc[idx, column] = new_col\n",
    "\n",
    "\n",
    "# Insert into main pivot\n",
    "pivot.loc[:, (\"Grounding by Prediction\")] = pivot_corr\n",
    "\n",
    "# Fix order of models\n",
    "pivot = pivot.reindex(archs, axis=\"columns\", level=\"Arch.\")\n",
    "\n",
    "display(pivot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pivot.loc[:, (\"Grounding by Prediction\", \"Acc. Corr.\")]\n",
    "caption = (\n",
    "    r\"\\emph{Vision - Test 1: Correlation to accuracy difference.}\"\n",
    "    \" Full results of the correlation between the similarity measures and the absolute accuracy differences for all architectures.\"\n",
    ")\n",
    "\n",
    "# Convert into latex file\n",
    "styled = pd.io.formats.style.Styler(\n",
    "    sub,\n",
    "    precision=2,\n",
    ")\n",
    "\n",
    "latex_str = styled.to_latex(\n",
    "    hrules=True,\n",
    "    position=\"h\",\n",
    "    label=\"tab:vision_results_test_1\",\n",
    "    caption=caption,\n",
    "    column_format=\"c||ccccccc\",\n",
    ")\n",
    "# print(latex_str)\n",
    "\n",
    "# ----- Manual modifications --------\n",
    "lines = latex_str.split(\"\\n\")\n",
    "\n",
    "# Add opening of resizebox and centering\n",
    "lines = lines[:3] + [r\"\\centering\", r\"\\resizebox{0.7\\linewidth}{!}{\"] + lines[3:]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Center headers\n",
    "pattern = r\"\\{r\\}\"\n",
    "replacement = r\"{c}\"\n",
    "lines = [re.sub(pattern, replacement, line) if i in [7, 8, 9] else line for i, line in enumerate(lines)]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove measure row\n",
    "lines.pop(11)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove modality row\n",
    "lines.pop(8)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove Arch. row\n",
    "lines.pop(8)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Add Test row\n",
    "lines = lines[:7] + [r\"Test & \\multicolumn{7}{c}{Accuracy Correlation} \\\\\"] + lines[7:]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Make every second row gray\n",
    "first_row_with_gray = 11\n",
    "final_rows_to_exclude = 4\n",
    "lines = [\n",
    "    r\"\\rowcolor{Gray}\" + line if i >= first_row_with_gray and (i - first_row_with_gray) % 2 == 0 else line for i, line in enumerate(lines[:-final_rows_to_exclude])\n",
    "] + lines[-final_rows_to_exclude:]\n",
    "\n",
    "# Add closing of resizebox\n",
    "lines = lines[:-2] + [r\"}\"] + lines[-2:]\n",
    "\n",
    "#\n",
    "latex_str = \"\\n\".join(lines)\n",
    "# print(latex_str)\n",
    "\n",
    "with open(\"tables/vision_test_1.tex\", \"w\") as f:\n",
    "    f.write(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pivot.loc[:, (\"Grounding by Prediction\", [\"JSD Corr.\", \"Disagr. Corr.\"])]\n",
    "caption = (\n",
    "    r\"\\emph{Vision - Test 2: Correlation to Output difference.} \"\n",
    "    \"Full results of the correlation between the similarity measures and the output differences for all architectures.\"\n",
    ")\n",
    "# display(sub.head())\n",
    "\n",
    "# Convert into latex file\n",
    "styled = pd.io.formats.style.Styler(\n",
    "    sub,\n",
    "    precision=2,\n",
    ")\n",
    "\n",
    "latex_str = styled.to_latex(\n",
    "    hrules=True,\n",
    "    position=\"h\",\n",
    "    label=\"tab:vision_results_test_2\",\n",
    "    caption=caption,\n",
    "    column_format=\"c||ccccccc|ccccccc\",\n",
    ")\n",
    "# print(latex_str)\n",
    "\n",
    "# ----- Manual modifications --------\n",
    "lines = latex_str.split(\"\\n\")\n",
    "\n",
    "# Add opening of resizebox and centering\n",
    "lines = lines[:3] + [r\"\\centering\", r\"\\resizebox{\\linewidth}{!}{\"] + lines[3:]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Center headers\n",
    "pattern = r\"\\{r\\}\"\n",
    "replacement = r\"{c}\"\n",
    "lines = [re.sub(pattern, replacement, line) if i in [7, 8, 9] else line for i, line in enumerate(lines)]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove measure row\n",
    "lines.pop(13)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove modality row\n",
    "lines.pop(10)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove Arch. row\n",
    "lines.pop(10)\n",
    "print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "\n",
    "# Make every second row gray\n",
    "first_row_with_gray = 12\n",
    "final_rows_to_exclude = 4\n",
    "lines = [\n",
    "    r\"\\rowcolor{Gray}\" + line if i >= first_row_with_gray and (i - first_row_with_gray) % 2 == 0 else line for i, line in enumerate(lines[:-final_rows_to_exclude])\n",
    "] + lines[-final_rows_to_exclude:]\n",
    "\n",
    "# Add closing of resizebox\n",
    "lines = lines[:-2] + [r\"}\"] + lines[-2:]\n",
    "\n",
    "#\n",
    "latex_str = \"\\n\".join(lines)\n",
    "# print(latex_str)\n",
    "\n",
    "with open(\"tables/vision_test_2.tex\", \"w\") as f:\n",
    "    f.write(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3 - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [\n",
    "    (\n",
    "        r\"\\emph{Vision - Test 3: Random Labels.} \"\n",
    "    ),\n",
    "    (\n",
    "        r\"\\emph{Vision - Test 4: Shortcut Affinity.} \" \\\n",
    "        \"Full results of the similarity measures for distinguishing model groups trained with shortcuts of various correlation to the image label.\"\n",
    "    ),\n",
    "    (\n",
    "        r\"\\emph{Vision - Test 5: Augmentation.} \" \\\n",
    "        \"Full results of the similarity measures for distinguishing model groups based on different additive gaussian noise augmentation used during training.\"\n",
    "    ),\n",
    "    (\n",
    "        r\"\\emph{Vision - Test 6: Monotonicity.} \"\\\n",
    "        \"Full results of the similarity measures for the monotonicity test.\"\n",
    "    )\n",
    "]\n",
    "columns = [\n",
    "    [\"Random Labels\"],\n",
    "    [\"Shortcuts\"],\n",
    "    [\"Augmentation\"],\n",
    "    [\"Layer Mono.\"],\n",
    "]\n",
    "\n",
    "for i, column, caption in zip(range(3, 7), columns, captions):\n",
    "    sub = pivot.loc[:, (\"Grounding by Design\", column)]\n",
    "\n",
    "    display(sub.head())\n",
    "\n",
    "    # Convert into latex file\n",
    "    styled = pd.io.formats.style.Styler(\n",
    "        sub,\n",
    "        precision=2,\n",
    "    )\n",
    "\n",
    "    latex_str = styled.to_latex(\n",
    "        hrules=True,\n",
    "        position=\"h\",\n",
    "        label=f\"tab:vision_results_test_{i}\",\n",
    "        caption=caption,\n",
    "        column_format=\"c||ccccccc|ccccccc\",\n",
    "    )\n",
    "    # print(latex_str)\n",
    "\n",
    "    # ----- Manual modifications --------\n",
    "    lines = latex_str.split(\"\\n\")\n",
    "\n",
    "    # Add opening of resizebox and centering\n",
    "    lines = lines[:3] + [r\"\\centering\", r\"\\resizebox{\\linewidth}{!}{\"] + lines[3:]\n",
    "    # print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "    # Center headers\n",
    "    pattern = r\"\\{r\\}\"\n",
    "    replacement = r\"{c}\"\n",
    "    lines = [re.sub(pattern, replacement, line) if i in [7, 8, 9] else line for i, line in enumerate(lines)]\n",
    "    # print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "    # Remove measure row\n",
    "    lines.pop(13)\n",
    "    # print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "    # Remove modality row\n",
    "    lines.pop(10)\n",
    "    # print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "    # Remove Arch. row\n",
    "    lines.pop(10)\n",
    "    print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "    # Make every second row gray\n",
    "    first_row_with_gray = 12\n",
    "    final_rows_to_exclude = 4\n",
    "    lines = [\n",
    "        r\"\\rowcolor{Gray}\" + line if i >= first_row_with_gray and (i - first_row_with_gray) % 2 == 0 else line for i, line in enumerate(lines[:-final_rows_to_exclude])\n",
    "    ] + lines[-final_rows_to_exclude:]\n",
    "\n",
    "    # Add closing of resizebox\n",
    "    lines = lines[:-2] + [r\"}\"] + lines[-2:]\n",
    "\n",
    "    #\n",
    "    latex_str = \"\\n\".join(lines)\n",
    "    # print(latex_str)\n",
    "\n",
    "    with open(f\"tables/vision_test_{i}.tex\", \"w\") as f:\n",
    "        f.write(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select language results\n",
    "datasets = [\"Cora\", \"Flickr\", \"OGBN-Arxiv\"]\n",
    "archs = [\"GCN\", \"SAGE\", \"GAT\", \"PGNN\"]\n",
    "idx = data[\"Dataset\"].isin(datasets) & data[\"Arch.\"].isin(archs)\n",
    "tests_with_pvals = [\"Acc. Corr.\", \"JSD Corr.\", \"Disagr. Corr.\"]\n",
    "\n",
    "\n",
    "# Create pivot table\n",
    "pivot = pd.pivot_table(\n",
    "    data.loc[idx],  # type: ignore\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=\"value\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=\"Sim Meas.\")\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Test\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "display(pivot.head(3))\n",
    "\n",
    "# Turn values into strings for manipulation with significance markers\n",
    "unpivot = pivot.unstack().reset_index()  # values will be in col \"0\"\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].astype(\"str\")\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].apply(lambda x: f\"{round(x, 2):.2f}\")\n",
    "pivot = unpivot.pivot(\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=1,\n",
    ")\n",
    "unpivot\n",
    "display(pivot.head(3))\n",
    "\n",
    "# Highlight the best values by bolding\n",
    "for column in pivot.columns:\n",
    "    col = pivot.loc[:, column].astype(\"float\")\n",
    "    idx = col == col.max()\n",
    "    pivot.loc[idx, column] = pivot.loc[idx, column].apply(lambda s: r\"\\textbf{\" + s + \"}\")\n",
    "display(pivot.head(3))\n",
    "\n",
    "\n",
    "# Add significance markers\n",
    "# 1) select data that should get markers\n",
    "idx = data[\"Dataset\"].isin(datasets) & data[\"Arch.\"].isin(archs) & data.Test.isin(tests_with_pvals)\n",
    "data_corr = data.loc[idx].copy()\n",
    "\n",
    "# 2) Create new column with value and marker\n",
    "data_corr[\"val_comb\"] = data_corr[\"value\"].apply(lambda x: f\"{round(x, ndigits=2):.2f}\") + data_corr[\"pval\"].apply(\n",
    "    pval_str\n",
    ")\n",
    "display(data_corr.head(3))\n",
    "\n",
    "# 3) Create pivot table for values with markers that can be inserted into the main pivot table\n",
    "pivot_corr = (\n",
    "    data_corr.pivot(\n",
    "        index=\"Sim Meas.\",\n",
    "        columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "        values=[\"val_comb\"],\n",
    "    )\n",
    "    .sort_values(by=\"Sim Meas.\")\n",
    "    .reindex(column_order, axis=\"columns\", level=\"Test\")\n",
    "    .loc[:, \"val_comb\"]\n",
    ")\n",
    "display(pivot_corr.head())\n",
    "\n",
    "# 4) Highlight the best scores by bolding\n",
    "for column in pivot_corr.columns:\n",
    "    col = pivot_corr.loc[:, column].apply(floatify).astype(\"float\")\n",
    "    identifiers = pivot_corr.loc[:, column].apply(separate_significance_indicator)\n",
    "    idx = col == col.max()\n",
    "    new_col = col.apply(lambda x: f\"{x:.2f}\").apply(lambda s: r\"\\textbf{\" + s + \"}\") + identifiers\n",
    "    pivot_corr.loc[idx, column] = new_col\n",
    "\n",
    "\n",
    "# Insert into main pivot\n",
    "pivot.loc[:, (\"Grounding by Prediction\")] = pivot_corr\n",
    "\n",
    "# Fix order of models\n",
    "pivot = pivot.reindex(archs, axis=\"columns\", level=\"Arch.\")\n",
    "\n",
    "display(pivot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pivot.loc[:, (\"Grounding by Prediction\", \"Acc. Corr.\")]\n",
    "caption = (\n",
    "    r\"\\emph{Graph - Test 1: Correlation to accuracy difference.}\"\n",
    ")\n",
    "\n",
    "# Convert into latex file\n",
    "styled = pd.io.formats.style.Styler(\n",
    "    sub,\n",
    "    precision=2,\n",
    ")\n",
    "\n",
    "latex_str = styled.to_latex(\n",
    "    hrules=True,\n",
    "    position=\"h\",\n",
    "    label=\"tab:graph_results_test_1\",\n",
    "    caption=caption,\n",
    "    column_format=\"l||rrrr|rrr|rrr||\",\n",
    ")\n",
    "# print(latex_str)\n",
    "\n",
    "# ----- Manual modifications --------\n",
    "lines = latex_str.split(\"\\n\")\n",
    "\n",
    "# Add opening of resizebox and centering\n",
    "lines = lines[:3] + [r\"\\centering\", r\"\\resizebox{0.7\\linewidth}{!}{\"] + lines[3:]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Center headers\n",
    "pattern = r\"\\{r\\}\"\n",
    "replacement = r\"{c}\"\n",
    "lines = [re.sub(pattern, replacement, line) if i in [7, 8, 9] else line for i, line in enumerate(lines)]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove measure row\n",
    "lines.pop(11)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove modality row\n",
    "lines.pop(8)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "\n",
    "# Add Test row\n",
    "lines = lines[:7] + [r\"Test & \\multicolumn{10}{c}{Accuracy Correlation} \\\\\"] + lines[7:]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Make every second row gray\n",
    "first_row_with_gray = 12\n",
    "final_rows_to_exclude = 4\n",
    "lines = [\n",
    "    r\"\\rowcolor{Gray}\" + line if i >= first_row_with_gray and (i - first_row_with_gray) % 2 == 0 else line for i, line in enumerate(lines[:-final_rows_to_exclude])\n",
    "] + lines[-final_rows_to_exclude:]\n",
    "\n",
    "# Add closing of resizebox\n",
    "lines = lines[:-2] + [r\"}\"] + lines[-2:]\n",
    "\n",
    "#\n",
    "latex_str = \"\\n\".join(lines)\n",
    "# print(latex_str)\n",
    "\n",
    "with open(\"tables/graph_test_1.tex\", \"w\") as f:\n",
    "    f.write(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pivot.loc[:, (\"Grounding by Prediction\", [\"JSD Corr.\", \"Disagr. Corr.\"])]\n",
    "caption = (\n",
    "    r\"\\emph{Graph - Test 2: Correlation to Output difference.} \"\n",
    "    \"Full results of the correlation between the similarity measures and the output differences for all architectures.\"\n",
    ")\n",
    "# display(sub.head())\n",
    "\n",
    "# Convert into latex file\n",
    "styled = pd.io.formats.style.Styler(\n",
    "    sub,\n",
    "    precision=2,\n",
    ")\n",
    "\n",
    "latex_str = styled.to_latex(\n",
    "    hrules=True,\n",
    "    position=\"h\",\n",
    "    label=\"tab:graph_results_test_2\",\n",
    "    caption=caption,\n",
    "    column_format=\"l||rrrr|rrr|rrr||rrrr|rrr|rrr\",\n",
    ")\n",
    "# print(latex_str)\n",
    "\n",
    "# ----- Manual modifications --------\n",
    "lines = latex_str.split(\"\\n\")\n",
    "\n",
    "# Add opening of resizebox and centering\n",
    "lines = lines[:3] + [r\"\\centering\", r\"\\resizebox{\\linewidth}{!}{\"] + lines[3:]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Center headers\n",
    "pattern = r\"\\{r\\}\"\n",
    "replacement = r\"{c}\"\n",
    "lines = [re.sub(pattern, replacement, line) if i in [6, 7, 8, 9, 10, 11] else line for i, line in enumerate(lines)]\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove measure row\n",
    "lines.pop(13)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "# Remove modality row\n",
    "lines.pop(10)\n",
    "# print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "\n",
    "# Make every second row gray\n",
    "first_row_with_gray = 13\n",
    "final_rows_to_exclude = 4\n",
    "lines = [\n",
    "    r\"\\rowcolor{Gray}\" + line if i >= first_row_with_gray and (i - first_row_with_gray) % 2 == 0 else line for i, line in enumerate(lines[:-final_rows_to_exclude])\n",
    "] + lines[-final_rows_to_exclude:]\n",
    "\n",
    "# Add closing of resizebox\n",
    "lines = lines[:-2] + [r\"}\"] + lines[-2:]\n",
    "\n",
    "#\n",
    "latex_str = \"\\n\".join(lines)\n",
    "# print(latex_str)\n",
    "\n",
    "with open(\"tables/graph_test_2.tex\", \"w\") as f:\n",
    "    f.write(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3 - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [\n",
    "    (\n",
    "        r\"\\emph{Graph - Test 3: Random Labels.} \"\n",
    "    ),\n",
    "    (\n",
    "        r\"\\emph{Graph - Test 4: Shortcut Affinity.} \"\n",
    "    ),\n",
    "    (\n",
    "        r\"\\emph{Graph - Test 5: Augmentation.} \"\n",
    "    ),\n",
    "    (\n",
    "        r\"\\emph{Graph - Test 6: Monotonicity.} \"\n",
    "    )\n",
    "]\n",
    "columns = [\n",
    "    [\"Random Labels\"],\n",
    "    [\"Shortcuts\"],\n",
    "    [\"Augmentation\"],\n",
    "    [\"Layer Mono.\"],\n",
    "]\n",
    "\n",
    "for i, column, caption in zip(range(3, 7), columns, captions):\n",
    "    sub = pivot.loc[:, (\"Grounding by Design\", column)]\n",
    "\n",
    "    display(sub.head())\n",
    "\n",
    "    # Convert into latex file\n",
    "    styled = pd.io.formats.style.Styler(\n",
    "        sub,\n",
    "        precision=2,\n",
    "    )\n",
    "\n",
    "    latex_str = styled.to_latex(\n",
    "        hrules=True,\n",
    "        position=\"h\",\n",
    "        label=f\"tab:graph_results_test_{i}\",\n",
    "        caption=caption,\n",
    "        column_format=\"c||ccc|ccc|ccc|ccc|ccc|ccc\" if \"Random Labels\" in column else \"c||cccc|ccc|ccc|cccc|ccc|ccc\",\n",
    "    )\n",
    "    # print(latex_str)\n",
    "\n",
    "    # ----- Manual modifications --------\n",
    "    lines = latex_str.split(\"\\n\")\n",
    "\n",
    "    # Add opening of resizebox and centering\n",
    "    lines = lines[:3] + [r\"\\centering\", r\"\\resizebox{\\linewidth}{!}{\"] + lines[3:]\n",
    "    # print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "    # Center headers\n",
    "    pattern = r\"\\{r\\}\"\n",
    "    replacement = r\"{c}\"\n",
    "    lines = [re.sub(pattern, replacement, line) if i in [7, 8, 9, 10, 11, 12] else line for i, line in enumerate(lines)]\n",
    "    # print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "    # Remove measure row\n",
    "    lines.pop(13)\n",
    "    # print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "    # Remove modality row\n",
    "    lines.pop(10)\n",
    "    # print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "    # Remove Arch. row\n",
    "    # lines.pop(10)\n",
    "    # print(\"\\n\".join([f\"{i}: {line}\" for i, line in enumerate(lines)]))\n",
    "\n",
    "\n",
    "    # Make every second row gray\n",
    "    first_row_with_gray = 13\n",
    "    final_rows_to_exclude = 4\n",
    "    lines = [\n",
    "        r\"\\rowcolor{Gray}\" + line if i >= first_row_with_gray and (i - first_row_with_gray) % 2 == 0 else line for i, line in enumerate(lines[:-final_rows_to_exclude])\n",
    "    ] + lines[-final_rows_to_exclude:]\n",
    "\n",
    "    # Add closing of resizebox\n",
    "    lines = lines[:-2] + [r\"}\"] + lines[-2:]\n",
    "\n",
    "    #\n",
    "    latex_str = \"\\n\".join(lines)\n",
    "    # print(latex_str)\n",
    "\n",
    "    with open(f\"tables/graph_test_{i}.tex\", \"w\") as f:\n",
    "        f.write(latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
