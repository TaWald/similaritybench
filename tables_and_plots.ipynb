{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing and Plotting Results\n",
    "\n",
    "Contains two sections:\n",
    "1. How to create a summary table.\n",
    "2. How to create plots showing the ranks of the similarity measures.\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "This section of the notebook, creates the overview table in our paper. This code can be easily adjusted to also output more detailed tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.io.formats.style\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from repsim.benchmark.paths import BASE_PATH\n",
    "\n",
    "\n",
    "measure_to_abbrv = {\n",
    "    \"AlignedCosineSimilarity\": \"AlignCos\",\n",
    "    \"CKA\": \"CKA\",\n",
    "    \"ConcentricityDifference\": \"ConcDiff\",\n",
    "    \"DistanceCorrelation\": \"DistCorr\",\n",
    "    \"EigenspaceOverlapScore\": \"EOS\",\n",
    "    \"GeometryScore\": \"GS\",\n",
    "    \"Gulp\": \"GULP\",\n",
    "    \"HardCorrelationMatch\": \"HardCorr\",\n",
    "    \"IMDScore\": \"IMD\",\n",
    "    \"JaccardSimilarity\": \"Jaccard\",\n",
    "    \"LinearRegression\": \"LinReg\",\n",
    "    \"MagnitudeDifference\": \"MagDiff\",\n",
    "    \"OrthogonalAngularShapeMetricCentered\": \"AngShape\",\n",
    "    \"OrthogonalProcrustesCenteredAndNormalized\": \"OrthProc\",\n",
    "    \"PWCCA\": \"PWCCA\",\n",
    "    \"PermutationProcrustes\": \"PermProc\",\n",
    "    \"ProcrustesSizeAndShapeDistance\": \"ProcDist\",\n",
    "    \"RSA\": \"RSA\",\n",
    "    \"RSMNormDifference\": \"RSMDiff\",\n",
    "    \"RankSimilarity\": \"RankSim\",\n",
    "    \"SVCCA\": \"SVCCA\",\n",
    "    \"SecondOrderCosineSimilarity\": \"2nd-Cos\",\n",
    "    \"SoftCorrelationMatch\": \"SoftCorr\",\n",
    "    \"UniformityDifference\": \"UnifDiff\",\n",
    "    \"RTD\": \"RTD\",\n",
    "}\n",
    "\n",
    "measure_types = [\n",
    "    (\"AlignCos\", \"Alignment\"),\n",
    "    (\"HardCorr\", \"Alignment\"),\n",
    "    (\"AngShape\", \"Alignment\"),\n",
    "    (\"LinReg\", \"Alignment\"),\n",
    "    (\"OrthProc\", \"Alignment\"),\n",
    "    (\"PermProc\", \"Alignment\"),\n",
    "    (\"ProcDist\", \"Alignment\"),\n",
    "    (\"SoftCorr\", \"Alignment\"),\n",
    "\n",
    "    (\"EOS\", \"RSM\"),\n",
    "    (\"CKA\", \"RSM\"),\n",
    "    (\"DistCorr\", \"RSM\"),\n",
    "    (\"GULP\", \"RSM\"),\n",
    "    (\"RSA\", \"RSM\"),\n",
    "    (\"RSMDiff\", \"RSM\"),\n",
    "\n",
    "    (\"MagDiff\", \"Statistic\"),\n",
    "    (\"ConcDiff\", \"Statistic\"),\n",
    "    (\"UnifDiff\", \"Statistic\"),\n",
    "\n",
    "    (\"GS\", \"Topology\"),\n",
    "    (\"IMD\", \"Topology\"),\n",
    "    (\"RTD\", \"Topology\"),\n",
    "\n",
    "    (\"Jaccard\", \"Neighbors\"),\n",
    "    (\"RankSim\", \"Neighbors\"),\n",
    "    (\"2nd-Cos\", \"Neighbors\"),\n",
    "\n",
    "    (\"PWCCA\", \"CCA\"),\n",
    "    (\"SVCCA\", \"CCA\"),\n",
    "\n",
    "]\n",
    "\n",
    "measure_type_order = [\"CCA\", \"Alignment\", \"RSM\", \"Neighbors\", \"Topology\", \"Statistic\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_dfs = []\n",
    "# nlp_root = BASE_PATH /\"paper_results\" / \"nlp\"\n",
    "# for path in nlp_root.glob(\"*.csv\"):\n",
    "#     df = pd.read_csv(path, index_col=0)\n",
    "#     setting = path.name.split(\"_\")[0]\n",
    "\n",
    "#     pattern = r'(?<=_)sst2(?=_)|(?<=_)mnli(?=_)'\n",
    "#     match = re.search(pattern, path.name)\n",
    "#     assert match is not None\n",
    "#     dataset = match.group(0)\n",
    "\n",
    "#     df[\"Setting\"] = setting\n",
    "#     df[\"Dataset\"] = dataset\n",
    "#     cleaned_dfs.append(df)\n",
    "\n",
    "# data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "# nlp_data = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "nlp_root = BASE_PATH /\"paper_results\" / \"nlp_iclr\"\n",
    "for path in nlp_root.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    setting = path.name.split(\"_\")[0]\n",
    "\n",
    "    pattern = r'(?<=_)sst2(?=_)|(?<=_)mnli(?=_)'\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    token = path.name.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    if \"smollm\" in path.name:\n",
    "        # not true, but we want to group standard non-aggregated token results for the llm with the cls token results for bert and albert\n",
    "        token = \"cls\"\n",
    "\n",
    "    df[\"Token\"] = token\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "nlp_data = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "root = BASE_PATH /\"paper_results\" /\"graph\"\n",
    "for path in root.glob(\"*.csv\"):\n",
    "    if path.name.endswith(\"backup.csv\"):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    pattern = r\"augmentation|label_test|layer_test|output_correlation|shortcut\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    pattern_to_setting = {\n",
    "        \"augmentation\": \"aug\",\n",
    "        \"label_test\": \"mem\",\n",
    "        \"layer_test\": \"mono\",\n",
    "        \"output_correlation\": \"correlation\",\n",
    "        \"shortcut\": \"sc\",\n",
    "    }\n",
    "    setting = pattern_to_setting[match.group(0)]\n",
    "\n",
    "    pattern = r\"(?<=_)cora(?=_)|(?<=_)flickr(?=_)|(?<=_)ogbn-arxiv(?=_)\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "graph_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data[(graph_data.representation_dataset==\"cora\") & (graph_data.Setting == \"correlation\") & (graph_data.quality_measure == \"spearmanr\")].groupby([\"architecture\", \"functional_similarity_measure\",\"similarity_measure\"]).count()\n",
    "graph_data[(graph_data.representation_dataset==\"cora\") & (graph_data.Setting == \"correlation\") & (graph_data.quality_measure == \"spearmanr\") & (graph_data.similarity_measure == \"AlignedCosineSimilarity\") & (graph_data.architecture == \"GCN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "root = BASE_PATH /\"paper_results\" /\"vision\"\n",
    "for path in root.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    pattern = r\"aug|mem|mono|correlation|sc\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    pattern_to_setting = {\n",
    "        \"aug\": \"aug\",\n",
    "        \"mem\": \"mem\",\n",
    "        \"mono\": \"mono\",\n",
    "        \"correlation\": \"correlation\",\n",
    "        \"sc\": \"sc\",\n",
    "    }\n",
    "    setting = pattern_to_setting[match.group(0)]\n",
    "\n",
    "    pattern = r\"(?<=_)in100(?=_)|(?<=_)c100(?=_)\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "vision_data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Pivot\n",
    "\n",
    "Step 2: Combine data into a big dataframe, clean up column names etc., and select data to be shown in table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Combine data\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "data = pd.concat([nlp_data, graph_data, vision_data])\n",
    "print(data.columns)\n",
    "\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"functional_similarity_measure\": \"Functional Similarity Measure\",\n",
    "        \"similarity_measure\": \"Representational Similarity Measure\",\n",
    "        \"quality_measure\": \"Quality Measure\",\n",
    "    }\n",
    ")\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"value\"] = data.loc[idx, \"corr\"]\n",
    "\n",
    "idx = (data.Setting == \"correlation\") & (data[\"Functional Similarity Measure\"] == \"AbsoluteAccDiff\")\n",
    "data.loc[idx, \"Setting\"] = \"acc_corr\"\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Exclude data not to be shown in table.\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "idx = (data.Setting == \"correlation\") & (data[\"Functional Similarity Measure\"] != \"JSD\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "idx = (data.Setting.isin([\"aug\", \"mem\", \"sc\"])) & (data[\"Quality Measure\"] != \"AUPRC\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "idx = (data.Setting.isin([\"correlation\", \"acc_corr\"])) & (data[\"Quality Measure\"] != \"spearmanr\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "# idx = (data.Setting.isin([\"mono\"])) & (data[\"Quality Measure\"] != \"violation_rate\")\n",
    "idx = (data.Setting.isin([\"mono\"])) & (data[\"Quality Measure\"] != \"correlation\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "idx = (data.Token.isin([\"mean\"]))\n",
    "data = data.loc[~idx]\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Clean up names etc.\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def beautify_df(data):\n",
    "    data.loc[:, \"Representational Similarity Measure\"] = data[\"Representational Similarity Measure\"].map(\n",
    "        measure_to_abbrv\n",
    "    )\n",
    "    data.loc[:, \"architecture\"] = data[\"architecture\"].map(\n",
    "        {\n",
    "            \"smollm2-1.7b\": \"SmolLM2\",\n",
    "            \"albert-base-v2\": \"ALBERT\",\n",
    "            \"BERT-L\": \"BERT\",\n",
    "            \"GCN\": \"GCN\",\n",
    "            \"GAT\": \"GAT\",\n",
    "            \"GraphSAGE\": \"SAGE\",\n",
    "            \"VGG11\": \"VGG11\",\n",
    "            \"VGG19\": \"VGG19\",\n",
    "            \"ResNet18\": \"RNet18\",\n",
    "            \"ResNet34\": \"RNet34\",\n",
    "            \"ResNet101\": \"RNet101\",\n",
    "            \"ViT_B32\": \"ViT_B32\",\n",
    "            \"ViT_L32\": \"ViT_L32\",\n",
    "            \"PGNN\": \"P-GNN\",\n",
    "        }\n",
    "    )\n",
    "    data.loc[:, \"domain\"] = data[\"domain\"].map({\"NLP\": \"Text\", \"GRAPHS\": \"Graph\", \"VISION\": \"Vision\"})\n",
    "    data.loc[:, \"Dataset\"] = data[\"Dataset\"].map(\n",
    "        {\n",
    "            \"mnli_aug_rate0\": \"MNLI\",\n",
    "            \"mnli_mem_rate0\": \"MNLI\",\n",
    "            \"mnli\": \"MNLI\",\n",
    "            \"sst2_sc_rate0558\": \"SST2\",\n",
    "            \"sst2_mem_rate0\": \"SST2\",\n",
    "            \"sst2_sft\": \"SST2\",\n",
    "            \"sst2_sft_sc_rate0558\": \"SST2\",\n",
    "            \"mnli_sc_rate0354\": \"MNLI\",\n",
    "            \"sst2_aug_rate0\": \"SST2\",\n",
    "            \"sst2\": \"SST2\",\n",
    "            \"flickr\": \"flickr\",\n",
    "            \"ogbn-arxiv\": \"arXiv\",\n",
    "            \"cora\": \"Cora\",\n",
    "            \"in100\": \"IN100\",\n",
    "            \"c100\": \"CIFAR100\",\n",
    "        }\n",
    "    )\n",
    "    data.loc[:, \"Setting\"] = data[\"Setting\"].map(\n",
    "        {\n",
    "            \"aug\": \"Augmentation\",\n",
    "            \"mem\": \"Random Labels\",\n",
    "            \"correlation\": \"JSD Corr.\",\n",
    "            \"acc_corr\": \"Acc Corr.\",\n",
    "            \"mono\": \"Layer Mono.\",\n",
    "            \"sc\": \"Shortcuts\",\n",
    "        }\n",
    "    )\n",
    "    column_order = [\"Acc Corr.\", \"JSD Corr.\", \"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]\n",
    "    data.loc[:, \"Setting\"] = pd.Categorical(\n",
    "        data[\"Setting\"],\n",
    "        categories=column_order,\n",
    "        ordered=True,\n",
    "    )\n",
    "    data.loc[:, \"Quality Measure\"] = data[\"Quality Measure\"].map(\n",
    "        {\"violation_rate\": \"Conformity Rate\", \"AUPRC\": \"AUPRC\", \"spearmanr\": \"Spearman\", \"correlation\": \"Spearman\"}\n",
    "    )\n",
    "    data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"] = (\n",
    "        1 - data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"]\n",
    "    )  # must be run in conjunction with the above renaming\n",
    "\n",
    "    data = data.rename(\n",
    "        columns={\n",
    "            \"domain\": \"Domain\",\n",
    "            \"architecture\": \"Arch.\",\n",
    "            \"Representational Similarity Measure\": \"Sim Meas.\",\n",
    "            \"Quality Measure\": \"Eval.\",\n",
    "            \"Setting\": \"Test\",\n",
    "        }\n",
    "    )\n",
    "    data = pd.merge(data, pd.DataFrame.from_records(measure_types, columns=[\"Sim Meas.\", \"Measure Type\"]), how=\"left\", on=\"Sim Meas.\")\n",
    "    data.loc[:, \"Measure Type\"] = pd.Categorical(data[\"Measure Type\"], categories=measure_type_order, ordered=True)\n",
    "    data.loc[data.Test.isin([\"Acc Corr.\", \"JSD Corr.\"]), \"Type\"] = \"Grounding by Prediction\"\n",
    "    data.loc[data.Test.isin([\"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]), \"Type\"] = (\n",
    "        \"Grounding by Design\"\n",
    "    )\n",
    "    return data, column_order\n",
    "\n",
    "\n",
    "data, column_order = beautify_df(data)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Create aggregated overview table\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "idx = data[\"Dataset\"].isin([\"MNLI\", \"flickr\", \"IN100\"]) & data[\"Arch.\"].isin([\"SAGE\", \"BERT\", \"RNet18\"])\n",
    "\n",
    "\n",
    "pivot = pd.pivot_table(\n",
    "    data.loc[idx],\n",
    "    index=[\"Measure Type\", \"Sim Meas.\"],  # <---\n",
    "    # index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Domain\", \"Dataset\", \"Arch.\"],\n",
    "    values=\"value\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=[\"Measure Type\", \"Sim Meas.\"], axis=\"index\")  # <---\n",
    "# pivot = pivot.sort_values(by=\"Sim Meas.\", axis=\"index\")\n",
    "pivot = pivot.reindex(measure_type_order, axis=\"index\", level=0)  # <---\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Test\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn values into strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpivot = pivot.unstack().unstack().dropna().reset_index()  # values will be in col \"0\"\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].astype(\"str\")\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].apply(lambda x: f\"{round(x, ndigits=2):.2f}\")\n",
    "pivot = unpivot.pivot(index=[\"Measure Type\", \"Sim Meas.\"],\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Domain\", \"Dataset\", \"Arch.\"],\n",
    "    values=1,)\n",
    "pivot = pivot.reindex(measure_type_order, axis=\"index\", level=0)  # <---\n",
    "\n",
    "unpivot\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight the best values by bolding\n",
    "for column in pivot.columns:\n",
    "    col = pivot.loc[:, column].astype(\"float\")\n",
    "    idx = col == col.max()\n",
    "    pivot.loc[idx, column] = pivot.loc[idx, column].apply(lambda s: r\"\\textbf{\" + s + \"}\")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = data[\"Dataset\"].isin([\"MNLI\", \"flickr\", \"IN100\"]) & data[\"Arch.\"].isin([\"SAGE\", \"BERT\", \"RNet18\"]) & data.Test.isin([\"Acc Corr.\", \"JSD Corr.\"])\n",
    "data_corr = data.loc[idx].copy()\n",
    "\n",
    "\n",
    "def pval_str(pval):\n",
    "    # if pval == pd.notna\n",
    "    if isinstance(pval, float):\n",
    "        if pval <= 0.01:\n",
    "            return r\"$^{**}$\"\n",
    "            # return r\"$^{\\dagger}$\"\n",
    "        if pval <= 0.05:\n",
    "            return r\"$^{*\\phantom{*}}$\"\n",
    "            # return r\"$^{\\ddagger}$\"\n",
    "    return r\"$^{\\phantom{**}}$\"\n",
    "\n",
    "def significance_via_text_style(pval):\n",
    "    if pval <= 0.01:\n",
    "        return [r\"\\underline{\\underline{\", r\"}}\"]\n",
    "    if pval <= 0.05:\n",
    "        return [r\"\\underline{\", r\"}\"]\n",
    "    return [\"\", \"\"]\n",
    "\n",
    "data_corr[\"val_comb\"] = data_corr[\"value\"].apply(lambda x: f\"{round(x, ndigits=2):.2f}\") + data_corr[\"pval\"].apply(pval_str)\n",
    "# data_corr[\"val_comb\"] = data_corr[\"pval\"].apply(significance_via_text_style).apply(lambda x: x[0]) + data_corr[\"value\"].apply(lambda x: f\"{round(x, ndigits=2):.2f}\") + data_corr[\"pval\"].apply(significance_via_text_style).apply(lambda x: x[1])\n",
    "data_corr\n",
    "\n",
    "pivot_corr = data_corr.pivot(\n",
    "    index=[\"Measure Type\", \"Sim Meas.\"],\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Domain\", \"Dataset\", \"Arch.\"],\n",
    "    values=[\"val_comb\"],\n",
    ").sort_values(\n",
    "    by=[\"Measure Type\", \"Sim Meas.\"],\n",
    ").reindex(\n",
    "    measure_type_order, axis=\"index\", level=0\n",
    ").reindex(\n",
    "    column_order, axis=\"columns\", level=\"Test\"\n",
    ").reindex(\n",
    "    [\"Graph\", \"Text\", \"Vision\"], axis=\"columns\", level=\"Domain\"\n",
    ").loc[:, \"val_comb\"]\n",
    "pivot_corr\n",
    "\n",
    "def floatify(s: str) -> str:\n",
    "    r\"\"\"Turn a string like '-0.10$^{\\phantom{**}}$' into '-0.10'\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    return s[:s.find(\"$\")]\n",
    "\n",
    "def separate_significance_indicator(s: str) -> str:\n",
    "    r\"\"\"Turn a string like '-0.10$^{\\phantom{**}}$' into '$^{\\phantom{**}}$'\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    return s[s.find(\"$\"):]\n",
    "\n",
    "for column in pivot_corr.columns:\n",
    "    col = pivot_corr.loc[:, column].apply(floatify).astype(\"float\")\n",
    "    identifiers = pivot_corr.loc[:, column].apply(separate_significance_indicator)\n",
    "    idx = col == col.max()\n",
    "    new_col = col.apply(lambda x: f\"{x:.2f}\").apply(lambda s: r\"\\textbf{\" + s + \"}\") + identifiers\n",
    "    pivot_corr.loc[idx, column] = new_col\n",
    "\n",
    "pivot_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot.loc[:, (\"Grounding by Prediction\")].astype(\"str\", copy=False)\n",
    "# pivot.loc[:, (\"Grounding by Prediction\", \"Acc Corr.\", \"Spearman\", \"Graph\", \"flickr\", \"SAGE\")] = pivot.loc[:, (\"Grounding by Prediction\", \"Acc Corr.\", \"Spearman\", \"Graph\", \"flickr\", \"SAGE\")].astype(\"str\")\n",
    "# pivot.loc[:, (\"Grounding by Prediction\")].dtypes\n",
    "\n",
    "pivot.loc[:, (\"Grounding by Prediction\")] = pivot_corr\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Convert into latex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled = pd.io.formats.style.Styler(\n",
    "    pivot,\n",
    "    precision=2,\n",
    ")\n",
    "\n",
    "# Highlight top value\n",
    "# latex_str = styled.highlight_max(axis=0, props=\"textbf:--rwrap;\").to_latex(\n",
    "#     hrules=True,\n",
    "#     position=\"t\",\n",
    "#     label=\"tab:result_overview\",\n",
    "# )\n",
    "latex_str = styled.to_latex(hrules=True, position=\"t\", label=\"tab:result_overview\",)\n",
    "\n",
    "\n",
    "# ----- Manual modifications --------\n",
    "latex_str = latex_str.split(\"\\n\")\n",
    "\n",
    "# Center headers\n",
    "pattern = r\"\\{r\\}\"\n",
    "replacement = r\"{c}\"\n",
    "latex_str = [re.sub(pattern, replacement, line) if i in [5, 6, 7] else line for i, line in enumerate(latex_str)]\n",
    "\n",
    "# Remove measure row\n",
    "latex_str.pop(11)\n",
    "\n",
    "# Add vertical bars\n",
    "line_no = 2\n",
    "# line_no = 3\n",
    "mod_line = latex_str[line_no][:18] + \"\".join([\"|rrr\"] * 6) + \"}\"\n",
    "latex_str[line_no] = mod_line\n",
    "\n",
    "# Make the left-most cells white\n",
    "latex_str = [\n",
    "    r\"\\cellcolor{white}\" + line if i >= 11 and (i - 11) % 2 == 0 else line for i, line in enumerate(latex_str[:-4])\n",
    "] + latex_str[-4:]\n",
    "latex_str = \"\\n\".join(latex_str)\n",
    "print(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([nlp_data, graph_data, vision_data])\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"value\"] = data.loc[idx, \"corr\"]\n",
    "\n",
    "idx = (data.Setting == \"correlation\") & (data[\"functional_similarity_measure\"] == \"AbsoluteAccDiff\")\n",
    "data.loc[idx, \"Setting\"] = \"acc_corr\"\n",
    "\n",
    "idx = (data.Setting == \"correlation\") & (data[\"functional_similarity_measure\"] == \"JSD\")\n",
    "data.loc[idx, \"Setting\"] = \"jsd_corr\"\n",
    "\n",
    "idx = (data.Setting == \"correlation\") & (data[\"functional_similarity_measure\"] == \"Disagreement\")\n",
    "data.loc[idx, \"Setting\"] = \"disagr_corr\"\n",
    "\n",
    "data.loc[:, \"similarity_measure\"] = data.loc[:, \"similarity_measure\"].map(measure_to_abbrv)\n",
    "\n",
    "data.functional_similarity_measure.unique()\n",
    "\n",
    "data = data.loc[~data.similarity_measure.isin([\"RTD\", \"IMD\"])]\n",
    "data = pd.merge(data, pd.DataFrame.from_records(measure_types, columns=[\"similarity_measure\", \"Measure Type\"]), how=\"left\", on=\"similarity_measure\")\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_mds(data: pd.DataFrame, suptitle=None):\n",
    "    data = data.copy()\n",
    "    # print(len(data))\n",
    "    data = data.sort_values(by=[\"Measure Type\", \"similarity_measure\"])\n",
    "    # print(len(data))\n",
    "    raw_scores = data.pivot_table(\n",
    "        index=[\"Measure Type\", \"similarity_measure\"],\n",
    "        columns=[\"quality_measure\", \"architecture\", \"representation_dataset\", \"Token\", \"Setting\", \"Dataset\"],\n",
    "        values=\"value\",\n",
    "        dropna=False,\n",
    "    ).dropna(axis=\"index\", how=\"all\").fillna(0)\n",
    "    # print(len(raw_scores))\n",
    "    # print(raw_scores.loc[raw_scores.index.get_level_values(\"similarity_measure\") == \"Jaccard\"])\n",
    "    raw_scores = raw_scores.reindex(measure_type_order, axis=\"index\", level=0).reset_index(level=0, drop=True)\n",
    "    print(len(raw_scores), suptitle)\n",
    "\n",
    "    from sklearn.manifold import TSNE\n",
    "    import numpy as np\n",
    "\n",
    "    # Create TSNE plot\n",
    "    tsne = TSNE(n_components=2, perplexity=3, random_state=42)\n",
    "    tsne_scores = tsne.fit_transform(raw_scores)\n",
    "\n",
    "    # Create MDS plot\n",
    "    from sklearn.manifold import MDS\n",
    "\n",
    "    mds = MDS(n_components=2, random_state=42)\n",
    "    mds_scores = mds.fit_transform(raw_scores)\n",
    "\n",
    "    # Create color maps for each measure type\n",
    "    measure_types_unique = data[\"Measure Type\"].unique()\n",
    "    color_maps = {\n",
    "        \"CCA\": plt.cm.Greys,\n",
    "        \"Alignment\": plt.cm.Purples,\n",
    "        \"Neighbors\": plt.cm.Greens,\n",
    "        \"RSM\": plt.cm.Reds,\n",
    "        \"Topology\": plt.cm.Oranges,\n",
    "        \"Statistic\": plt.cm.copper,\n",
    "    }\n",
    "\n",
    "    # Create a mapping of measures to colors based on their type\n",
    "    unique_measures = raw_scores.index\n",
    "    measure_to_type = data.groupby(\"similarity_measure\")[\"Measure Type\"].first()\n",
    "    colors = []\n",
    "    for measure in unique_measures:\n",
    "        measure_type = measure_to_type[measure]\n",
    "        type_idx = np.where(measure_types_unique == measure_type)[0][0]\n",
    "        # Get number of measures of this type\n",
    "        n_measures_of_type = (measure_to_type == measure_type).sum()\n",
    "        # Get position of this measure within its type\n",
    "        pos_in_type = (measure_to_type[:measure] == measure_type).sum()\n",
    "        # Create color gradient within type\n",
    "        color = color_maps.get(measure_type, plt.cm.Greys)(0.3 + (0.7 * pos_in_type / n_measures_of_type))\n",
    "        colors.append(color)\n",
    "\n",
    "    # Create subplot with TSNE and MDS side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Plot TSNE\n",
    "    for i, measure in enumerate(unique_measures):\n",
    "        ax1.scatter(tsne_scores[i, 0], tsne_scores[i, 1], c=[colors[i]], label=measure)\n",
    "        ax1.text(tsne_scores[i, 0], tsne_scores[i, 1], measure, fontsize=8)\n",
    "    ax1.set_title(\"t-SNE\")\n",
    "\n",
    "    # Plot MDS\n",
    "    for i, measure in enumerate(unique_measures):\n",
    "        ax2.scatter(mds_scores[i, 0], mds_scores[i, 1], c=[colors[i]], label=measure)\n",
    "        ax2.text(mds_scores[i, 0], mds_scores[i, 1], measure, fontsize=8)\n",
    "    ax2.set_title(\"MDS\")\n",
    "\n",
    "    if suptitle is not None:\n",
    "        fig.suptitle(suptitle)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_tsne_mds(data, suptitle=\"All domains\")\n",
    "plot_tsne_mds(data.loc[data.domain == \"NLP\"], suptitle=\"NLP\")\n",
    "plot_tsne_mds(data.loc[data.domain == \"GRAPHS\"], suptitle=\"Graphs\")\n",
    "plot_tsne_mds(data.loc[data.domain == \"VISION\"], suptitle=\"Vision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rankplots\n",
    "\n",
    "Requires section above to be run as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(\"paper\", style=\"white\", font_scale=1.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine data similarly to before, but do not filter out specific parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([nlp_data, graph_data, vision_data])\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"functional_similarity_measure\": \"Functional Similarity Measure\",\n",
    "        \"similarity_measure\": \"Representational Similarity Measure\",\n",
    "        \"quality_measure\": \"Quality Measure\",\n",
    "    }\n",
    ")\n",
    "data = data.reset_index()\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"value\"] = data.loc[idx, \"corr\"]\n",
    "\n",
    "idx = data[\"Quality Measure\"].isin([\"AUPRC\", \"spearmanr\", \"correlation\"])\n",
    "data = data.loc[idx]\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"Setting\"] = data.loc[idx, \"Setting\"] + data.loc[idx, \"Functional Similarity Measure\"]\n",
    "\n",
    "idx = ~(data.Setting == \"mono\")\n",
    "data.loc[idx, \"model\"] = \"agg\"\n",
    "\n",
    "idx = data.Token.isna()\n",
    "data.loc[idx, \"Token\"] = \"NA\"\n",
    "\n",
    "# idx = data.Token.isin([\"mean\"])\n",
    "# data = data.loc[~idx]\n",
    "\n",
    "data[\"rank\"] = data.groupby([\"domain\", \"Setting\", \"Dataset\", \"architecture\", \"model\", \"Token\"], as_index=True)[\"value\"].rank(\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "# combine layer mono results to equally weight experiments\n",
    "idx = data.model != \"agg\"\n",
    "data.loc[idx, \"rank\"] = data[idx].groupby([\"domain\", \"Setting\", \"Dataset\", \"architecture\", \"Token\"])[\"rank\"].mean().reset_index()\n",
    "data = data.drop_duplicates(subset=[\"domain\", \"Setting\", \"Dataset\", \"architecture\", \"Representational Similarity Measure\", \"Functional Similarity Measure\", \"Quality Measure\"])\n",
    "\n",
    "data.loc[:, \"Representational Similarity Measure\"] = data[\"Representational Similarity Measure\"].map(measure_to_abbrv)\n",
    "data.loc[:, \"architecture\"] = data[\"architecture\"].map(\n",
    "    {\n",
    "        \"smollm2-1.7b\": \"SmolLM2\",\n",
    "        \"albert-base-v2\": \"ALBERT\",\n",
    "        \"BERT-L\": \"BERT\",\n",
    "        \"GCN\": \"GCN\",\n",
    "        \"GAT\": \"GAT\",\n",
    "        \"GraphSAGE\": \"SAGE\",\n",
    "        \"VGG11\": \"VGG11\",\n",
    "        \"VGG19\": \"VGG19\",\n",
    "        \"ResNet18\": \"RNet18\",\n",
    "        \"ResNet34\": \"RNet34\",\n",
    "        \"ResNet101\": \"RNet101\",\n",
    "        \"ViT_B32\": \"ViT_B32\",\n",
    "        \"ViT_L32\": \"ViT_L32\",\n",
    "    }\n",
    ")\n",
    "data.loc[:, \"domain\"] = data[\"domain\"].map({\"NLP\": \"Language\", \"GRAPHS\": \"Graph\", \"VISION\": \"Vision\"})\n",
    "data.loc[:, \"Dataset\"] = data[\"Dataset\"].map(\n",
    "    {\n",
    "        \"mnli_aug_rate0\": \"MNLI\",\n",
    "        \"mnli_mem_rate0\": \"MNLI\",\n",
    "        \"mnli\": \"MNLI\",\n",
    "        \"sst2_sc_rate0558\": \"SST2\",\n",
    "        \"sst2_mem_rate0\": \"SST2\",\n",
    "        \"sst2_sft\": \"SST2\",\n",
    "        \"sst2_sft_sc_rate0558\": \"SST2\",\n",
    "        \"mnli_sc_rate0354\": \"MNLI\",\n",
    "        \"sst2_aug_rate0\": \"SST2\",\n",
    "        \"sst2\": \"SST2\",\n",
    "        \"flickr\": \"flickr\",\n",
    "        \"ogbn-arxiv\": \"arXiv\",\n",
    "        \"cora\": \"Cora\",\n",
    "        \"in100\": \"IN100\",\n",
    "        \"c100\": \"CIFAR100\",\n",
    "    }\n",
    ")\n",
    "data.loc[:, \"Setting\"] = data[\"Setting\"].map(\n",
    "    {\n",
    "        \"aug\": \"Augmentation\",\n",
    "        \"mem\": \"Random Labels\",\n",
    "        \"correlationJSD\": \"JSD Corr.\",\n",
    "        \"correlationAbsoluteAccDiff\": \"Acc Corr.\",\n",
    "        \"correlationDisagreement\": \"Disagr. Corr.\",\n",
    "        \"acc_corr\": \"Acc Corr.\",\n",
    "        \"mono\": \"Layer Mono.\",\n",
    "        \"sc\": \"Shortcuts\",\n",
    "    }\n",
    ")\n",
    "\n",
    "data.loc[:, \"Quality Measure\"] = data[\"Quality Measure\"].map(\n",
    "    {\"violation_rate\": \"Conformity Rate\", \"AUPRC\": \"AUPRC\", \"spearmanr\": \"Spearman\", \"correlation\": \"Spearman\"}\n",
    ")\n",
    "data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"] = (\n",
    "    1 - data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"]\n",
    ")  # must be run in conjunction with the above renaming\n",
    "\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"domain\": \"Modality\",\n",
    "        \"architecture\": \"Arch.\",\n",
    "        \"Representational Similarity Measure\": \"Sim Meas.\",\n",
    "        \"Quality Measure\": \"Eval.\",\n",
    "        \"Setting\": \"Scenario\",\n",
    "    }\n",
    ")\n",
    "\n",
    "data = data.sort_values(by=[\"Sim Meas.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Rank measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ranks = data.groupby([\"Modality\", \"Sim Meas.\"])[\"rank\"].agg([\"mean\", \"median\"]).reset_index()\n",
    "avg_ranks = avg_ranks.rename(columns={\"mean\": \"avg_rank\", \"median\": \"med_rank\"})\n",
    "avg_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.merge(data, avg_ranks).sort_values(by=[\"med_rank\"])\n",
    "plot_data = pd.merge(plot_data, pd.DataFrame.from_records(measure_types, columns=[\"Sim Meas.\", \"Measure Type\"]), how=\"left\", on=\"Sim Meas.\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, sharey=False, figsize=(7*0.8*3, 7))\n",
    "fig\n",
    "\n",
    "for i, mod in enumerate([\"Graph\", \"Language\", \"Vision\"]):\n",
    "# for i, mod in enumerate(plot_data.Modality.unique()):\n",
    "    # g = sns.catplot(\n",
    "    #     data=plot_data[plot_data.Modality == mod],\n",
    "    #     x=\"rank\",\n",
    "    #     y=\"Sim Meas.\",\n",
    "    #     hue=\"Measure Type\",\n",
    "    #     # hue=\"Modality\",\n",
    "    #     kind=\"box\",\n",
    "    #     height=7,\n",
    "    #     aspect=0.8,\n",
    "    #     col=\"Modality\",\n",
    "    #     palette=\"colorblind\",\n",
    "    #     # palette={\"Language\": \"C1\", \"Vision\": \"C2\", \"Graph\": \"C0\"},\n",
    "    #     legend=True if mod==\"Vision\" else False\n",
    "    #     # legend=False\n",
    "    # )\n",
    "    # ax = g.axes[0, 0]\n",
    "\n",
    "    ax = axes[i]\n",
    "    sns.boxplot(\n",
    "        data=plot_data[plot_data.Modality == mod],\n",
    "        x=\"rank\",\n",
    "        y=\"Sim Meas.\",\n",
    "        hue=\"Measure Type\",\n",
    "        hue_order=[\"Neighbors\", \"RSM\", \"Alignment\", \"Topology\", \"CCA\", \"Statistic\"],\n",
    "        # palette={\n",
    "        #     \"Neighbors\": \"C0\",\n",
    "        #     \"RSM\": \"C1\",\n",
    "        #     \"Alignment\": \"C2\",\n",
    "        #     \"Topology\": \"C3\",\n",
    "        #     \"CCA\": \"C4\",\n",
    "        #     \"Statistic\": \"C5\",\n",
    "        # },\n",
    "        palette=\"colorblind\",\n",
    "        legend=True if mod==\"Vision\" else False,\n",
    "        ax=ax,\n",
    "        # whis=(5.,95.)\n",
    "    )\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    ax.set_xlabel(\"Rank\")\n",
    "    ax.set_ylabel(\"Similarity Measures\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if mod == \"Graph\":\n",
    "        ax.set_title(\"Graphs\")\n",
    "    else:\n",
    "        ax.set_title(mod)\n",
    "\n",
    "    if mod == \"Vision\":\n",
    "        sns.move_legend(ax, loc=\"right\", bbox_to_anchor=(1.45,0.5))\n",
    "    # g.savefig(BASE_PATH / \"figs\" / f\"aggregated_ver_{mod}.pdf\", bbox_inches=\"tight\")\n",
    "    fig.savefig(BASE_PATH / \"figs\" / f\"aggregated_ver_{mod}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.merge(data, avg_ranks).sort_values(by=[\"med_rank\"])\n",
    "for mod in plot_data.Modality.unique():\n",
    "    for arch in plot_data[\"Arch.\"].unique():\n",
    "        subdata = plot_data[(plot_data.Modality == mod) & (plot_data[\"Arch.\"] == arch)]\n",
    "        if len(subdata) == 0:\n",
    "            continue\n",
    "\n",
    "        g = sns.catplot(\n",
    "            data=plot_data[(plot_data.Modality == mod) & (plot_data[\"Arch.\"] == arch)],\n",
    "            x=\"rank\",\n",
    "            y=\"Sim Meas.\",\n",
    "            hue=\"Modality\",\n",
    "            kind=\"box\",\n",
    "            height=7,\n",
    "            aspect=0.8,\n",
    "            col=\"Arch.\",\n",
    "            palette={\"Language\": \"C1\", \"Vision\": \"C2\", \"Graph\": \"C0\"},\n",
    "            legend=False\n",
    "        )\n",
    "        ax = g.axes[0, 0]\n",
    "        ax.set_xlabel(\"Rank\")\n",
    "        ax.set_ylabel(\"Similarity Measures\")\n",
    "\n",
    "        ax.set_title(f\"{arch} {mod}\")\n",
    "        # g.savefig(BASE_PATH / \"figs\" / f\"aggregated_ver_{mod}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Arch.\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for archs, fname in [\n",
    "    ([\"VGG11\", \"VGG19\"], \"VGGs\"),\n",
    "    ([\"RNet18\", \"RNet34\", \"RNet101\"], \"ResNets\")\n",
    "    ]:\n",
    "    avg_ranks = data[(data[\"Arch.\"].isin(archs))].groupby([\"Modality\", \"Sim Meas.\"])[\"rank\"].agg([\"mean\", \"median\"]).reset_index()\n",
    "    # avg_ranks = data[data[\"Arch.\"].isin(archs)].groupby([\"Modality\", \"Sim Meas.\"])[\"rank\"].agg([\"mean\", \"median\"]).reset_index()\n",
    "    avg_ranks = avg_ranks.rename(columns={\"mean\": \"avg_rank\", \"median\": \"med_rank\"})\n",
    "    avg_ranks\n",
    "\n",
    "    plot_data = pd.merge(data, avg_ranks).sort_values(by=\"med_rank\")\n",
    "    subdata = plot_data[(plot_data.Modality == \"Vision\") & (plot_data[\"Arch.\"].isin(archs))]\n",
    "\n",
    "    g = sns.catplot(\n",
    "        data=subdata,\n",
    "        x=\"rank\",\n",
    "        y=\"Sim Meas.\",\n",
    "        hue=\"Modality\",\n",
    "        kind=\"box\",\n",
    "        height=7,\n",
    "        aspect=0.8,\n",
    "        col=\"Modality\",\n",
    "        palette={\"Language\": \"C1\", \"Vision\": \"C2\", \"Graph\": \"C0\"},\n",
    "        legend=False\n",
    "    )\n",
    "    ax = g.axes[0, 0]\n",
    "    ax.set_xlabel(\"Rank\")\n",
    "    ax.set_ylabel(\"Similarity Measures\")\n",
    "\n",
    "    ax.set_title(f\"{fname}\")\n",
    "    g.savefig(BASE_PATH / \"figs\" / f\"aggregated_ver_{fname}.pdf\", bbox_inches=\"tight\")\n",
    "    print(BASE_PATH / \"figs\" / f\"aggregated_ver_{fname}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Test\n",
    "\n",
    "Uses only the AUPRC und spearman results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"Eval.\"].unique())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ranks = data.groupby([\"Modality\", \"Sim Meas.\", \"Scenario\"])[\"rank\"].agg([\"mean\", \"median\"]).reset_index()\n",
    "avg_ranks = avg_ranks.rename(columns={\"mean\": \"avg_rank\", \"median\": \"med_rank\"})\n",
    "avg_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.merge(data, avg_ranks).sort_values(by=[\"med_rank\"])\n",
    "for test in plot_data.Scenario.unique():\n",
    "    for mod in plot_data.Modality.unique():\n",
    "        subplot_data = plot_data[(plot_data.Scenario == test) & (plot_data.Modality == mod)]\n",
    "        # --------------------------- V1 ---------------------------------------\n",
    "        # g = sns.catplot(\n",
    "        #     data=plot_data[(plot_data.Scenario == test) & (plot_data.Modality == mod)],\n",
    "        #     x=\"rank\",\n",
    "        #     y=\"Sim Meas.\",\n",
    "        #     hue=\"Modality\",\n",
    "        #     kind=\"swarm\",\n",
    "        #     height=7,\n",
    "        #     aspect=0.8,\n",
    "        #     col=\"Modality\",\n",
    "        #     palette={\"Language\": \"C1\", \"Vision\": \"C2\", \"Graph\": \"C0\"},\n",
    "        #     legend=False\n",
    "        # )\n",
    "\n",
    "        # --------------------------- V2 ---------------------------------------\n",
    "        # fig, ax = plt.subplots(1, 1, figsize=(7, 7*0.8))\n",
    "        # g = sns.boxplot(\n",
    "        #     data=plot_data[(plot_data.Scenario == test) & (plot_data.Modality == mod)],\n",
    "        #     x=\"rank\",\n",
    "        #     y=\"Sim Meas.\",\n",
    "        #     hue=\"Modality\",\n",
    "        #     # height=7,\n",
    "        #     # aspect=0.8,\n",
    "        #     # col=\"Modality\",\n",
    "        #     palette={\"Language\": \"C1\", \"Vision\": \"C2\", \"Graph\": \"C0\"},\n",
    "        #     # legend=False,\n",
    "        #     ax=ax\n",
    "        # )\n",
    "        # g = sns.stripplot(\n",
    "        #     data=plot_data[(plot_data.Scenario == test) & (plot_data.Modality == mod)],\n",
    "        #     x=\"rank\",\n",
    "        #     y=\"Sim Meas.\",\n",
    "        #     hue=\"Modality\",\n",
    "        #     size=5,\n",
    "        #     # height=7,\n",
    "        #     # aspect=0.8,\n",
    "        #     # col=\"Modality\",\n",
    "        #     palette={\"Language\": \"C2\", \"Vision\": \"C3\", \"Graph\": \"C1\"},\n",
    "        #     # legend=False,\n",
    "        #     ax=ax\n",
    "        # )\n",
    "        # ------------------------------------------------------------------------\n",
    "\n",
    "        # # ax = g.axes[0, 0]\n",
    "        # for i in range(len(subplot_data[\"Sim Meas.\"].unique())):\n",
    "        #     if i % 2 == 0:\n",
    "        #         ax.fill_between([0, 23], [-0.5 + i, -0.5 + i], [0.5 + i, 0.5 + i], color=\"gray\", alpha=0.2)\n",
    "        # ax.set_xlabel(\"Rank\")\n",
    "        # ax.set_ylabel(\"Similarity Measures\")\n",
    "        # if mod == \"Graph\":\n",
    "        #     ax.set_title(f\"{test} (Graphs)\")\n",
    "        # else:\n",
    "        #     ax.set_title(f\"{test} ({mod})\")\n",
    "        # g.savefig(BASE_PATH / \"figs\" / f\"aggregated_ver_{mod}.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "        display(subplot_data.head(2))\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.merge(data, avg_ranks).sort_values(by=[\"med_rank\"])\n",
    "plot_data.loc[plot_data.Scenario.isin([\"Acc Corr.\", \"JSD Corr.\", \"Disagr. Corr.\"]), \"Type\"] = \"Grounding by Prediction\"\n",
    "plot_data.loc[plot_data.Scenario.isin([\"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]), \"Type\"] = (\n",
    "        \"Grounding by Design\"\n",
    "    )\n",
    "column_order = [\"Acc Corr.\", \"JSD Corr.\", \"Disagr. Corr.\", \"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Create pivot with mean values. The values are converted to string for combination with stddev\n",
    "pivot = pd.pivot_table(\n",
    "    plot_data,\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Scenario\", \"Eval.\", \"Modality\"],\n",
    "    values=\"value\",\n",
    "    aggfunc=\"mean\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=\"Sim Meas.\")\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Scenario\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "pivot\n",
    "\n",
    "unpivot = pivot.unstack().reset_index()  # values will be in col \"0\"\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].astype(\"str\")\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].apply(lambda x: str(round(x, 2)))\n",
    "pivot_mean = unpivot.pivot(index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Scenario\", \"Eval.\", \"Modality\"],\n",
    "    values=1,)\n",
    "unpivot\n",
    "pivot_mean\n",
    "\n",
    "# display(pivot.head())\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Create pivot with stddev values.\n",
    "pivot = pd.pivot_table(\n",
    "    plot_data,\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Scenario\", \"Eval.\", \"Modality\"],\n",
    "    values=\"value\",\n",
    "    aggfunc=\"std\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=\"Sim Meas.\")\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Scenario\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "pivot\n",
    "\n",
    "unpivot = pivot.unstack().reset_index()  # values will be in col \"0\"\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].astype(\"str\")\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].apply(lambda x: str(round(x, 2)))\n",
    "pivot_std = unpivot.pivot(index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Scenario\", \"Eval.\", \"Modality\"],\n",
    "    values=1,)\n",
    "unpivot\n",
    "pivot_std\n",
    "# display(pivot.head())\n",
    "\n",
    "# -----------------------------------------\n",
    "# Combine mean with stddev\n",
    "pivot_comb = pivot_mean + r\"$\\pm$\" + pivot_std\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Bold best metric scores\n",
    "def floatify(s: str) -> str:\n",
    "    \"\"\"Turn a string like '-0.10$\\pm$0.2' into '-0.10'\"\"\"\n",
    "    return s[:s.find(\"$\")]\n",
    "\n",
    "def separate_significance_indicator(s: str) -> str:\n",
    "    \"\"\"Turn a string like '-0.10$^{\\phantom{**}}$' into '$^{\\phantom{**}}$'\"\"\"\n",
    "    return s[s.find(\"$\"):]\n",
    "\n",
    "\n",
    "for column in pivot_comb.columns:\n",
    "    col = pivot_comb.loc[:, column].apply(floatify).astype(\"float\").copy()\n",
    "    stddev = pivot_comb.loc[:, column].apply(separate_significance_indicator)\n",
    "    idx = col == col.max()\n",
    "    new_col = col.apply(lambda x: f\"{x:.2f}\").map(lambda s: r\"\\textbf{\" + s + \"}\") + stddev.map(lambda s: r\"\\textbf{\" + s + \"}\")\n",
    "    pivot_comb.loc[idx, column] = new_col\n",
    "\n",
    "pivot_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled = pd.io.formats.style.Styler(\n",
    "    pivot_comb,\n",
    "    precision=2,\n",
    ")\n",
    "\n",
    "# Highlight top value\n",
    "# latex_str = styled.highlight_max(axis=0, props=\"textbf:--rwrap;\").to_latex(\n",
    "#     hrules=True,\n",
    "#     position=\"t\",\n",
    "#     label=\"tab:result_overview\",\n",
    "# )\n",
    "latex_str = styled.to_latex(hrules=True, position=\"t\", label=\"tab:results_agg_per_test\",)\n",
    "\n",
    "\n",
    "# ----- Manual modifications --------\n",
    "latex_str = latex_str.split(\"\\n\")\n",
    "\n",
    "# # Center headers\n",
    "# pattern = r\"\\{r\\}\"\n",
    "# replacement = r\"{c}\"\n",
    "# latex_str = [re.sub(pattern, replacement, line) if i in [5, 6, 7] else line for i, line in enumerate(latex_str)]\n",
    "\n",
    "# # Remove measure row\n",
    "# latex_str.pop(11)\n",
    "\n",
    "# # Add vertical bars\n",
    "# line_no = 2\n",
    "# # line_no = 3\n",
    "# mod_line = latex_str[line_no][:17] + \"\".join([\"|rrr\"] * 6) + \"}\"\n",
    "# latex_str[line_no] = mod_line\n",
    "\n",
    "# Make every second row gray\n",
    "latex_str = [\n",
    "    r\"\\rowcolor{Gray}\" + line if i >= 12 and (i - 12) % 2 == 0 else line for i, line in enumerate(latex_str[:-4])\n",
    "] + latex_str[-4:]\n",
    "latex_str = \"\\n\".join(latex_str)\n",
    "print(latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.merge(data, avg_ranks).sort_values(by=[\"med_rank\"])\n",
    "plot_data.loc[plot_data.Scenario.isin([\"Acc Corr.\", \"JSD Corr.\", \"Disagr. Corr.\"]), \"Type\"] = \"Grounding by Prediction\"\n",
    "plot_data.loc[plot_data.Scenario.isin([\"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]), \"Type\"] = (\n",
    "        \"Grounding by Design\"\n",
    "    )\n",
    "column_order = [\"Acc Corr.\", \"JSD Corr.\", \"Disagr. Corr.\", \"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Create pivot with mean ranks. The values are converted to string for combination with stddev\n",
    "pivot = pd.pivot_table(\n",
    "    plot_data,\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Modality\", \"Type\", \"Scenario\", \"Eval.\"],\n",
    "    values=\"rank\",\n",
    "    aggfunc=\"mean\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=\"Sim Meas.\")\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Scenario\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in data.Modality.unique():\n",
    "    print(mod)\n",
    "    subdata = pivot.loc[:, mod]\n",
    "    # display(subdata.head(3))\n",
    "    styled = pd.io.formats.style.Styler(\n",
    "        subdata,\n",
    "        precision=1,\n",
    "    )\n",
    "\n",
    "    # Highlight top value\n",
    "    latex_str = styled.highlight_min(axis=0, props=\"textbf:--rwrap;\").to_latex(\n",
    "        hrules=True,\n",
    "        position=\"t\",\n",
    "        label=\"tab:result_overview\",\n",
    "    )\n",
    "    latex_str = styled.to_latex(hrules=True, position=\"t\", label=\"tab:results_agg_per_test\",)\n",
    "\n",
    "\n",
    "    # ----- Manual modifications --------\n",
    "    latex_str = latex_str.split(\"\\n\")\n",
    "\n",
    "    # # Center headers\n",
    "    # pattern = r\"\\{r\\}\"\n",
    "    # replacement = r\"{c}\"\n",
    "    # latex_str = [re.sub(pattern, replacement, line) if i in [5, 6, 7] else line for i, line in enumerate(latex_str)]\n",
    "\n",
    "    # Remove measure row\n",
    "    latex_str.pop(7)\n",
    "\n",
    "    # Remove eval measure row\n",
    "    latex_str.pop(6)\n",
    "\n",
    "    # # Add vertical bars\n",
    "    # line_no = 2\n",
    "    # # line_no = 3\n",
    "    # mod_line = latex_str[line_no][:17] + \"\".join([\"|rrr\"] * 6) + \"}\"\n",
    "    # latex_str[line_no] = mod_line\n",
    "\n",
    "    # Make every second row gray\n",
    "    latex_str = [\n",
    "        r\"\\rowcolor{Gray}\" + line if i >= 7 and (i - 7) % 2 == 0 else line for i, line in enumerate(latex_str[:-4])\n",
    "    ] + latex_str[-4:]\n",
    "    latex_str = \"\\n\".join(latex_str)\n",
    "    print(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tabelle mit ranks als index und entries als metrics\n",
    "\n",
    "\"rank\" column: Rank des measures grouped by [\"domain\", \"Setting\", \"Dataset\", \"architecture\", \"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data = pd.merge(data.copy(), data.groupby([\"Modality\", \"Scenario\", \"Sim Meas.\"])[\"rank\"].mean().groupby([\"Modality\", \"Scenario\",]).rank().reset_index().rename(columns={\"rank\": \"rank_per_test_and_mod\"}))\n",
    "# display(plot_data)\n",
    "# plot_data.drop_duplicates(subset=[\"Modality\", \"Scenario\", \"Sim Meas.\"])\n",
    "\n",
    "# for mod in data.Modality.unique():\n",
    "#     subdata = plot_data.loc[plot_data.Modality == mod]\n",
    "#     pd.pivot(subdata, index=\"rank_per_test_and_mod\", columns=[\"Scenario\"], values=\"Sim Meas.\")\n",
    "# # data.groupby([\"Modality\", \"Scenario\"])[\"avg_rank\"].agg([\"mean\", \"median\"]).reset_index()\n",
    "\n",
    "# # avg_ranks.groupby([\"Modality\", \"Sim Meas.\", \"Scenario\"])[\"avg_rank\"].rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuttal PGNN tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_data.copy()\n",
    "\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"functional_similarity_measure\": \"Functional Similarity Measure\",\n",
    "        \"similarity_measure\": \"Representational Similarity Measure\",\n",
    "        \"quality_measure\": \"Quality Measure\",\n",
    "    }\n",
    ")\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"value\"] = data.loc[idx, \"corr\"]\n",
    "\n",
    "idx = (data.Setting == \"correlation\") & (data[\"Functional Similarity Measure\"] == \"AbsoluteAccDiff\")\n",
    "data.loc[idx, \"Setting\"] = \"acc_corr\"\n",
    "\n",
    "idx = (data.Setting == \"correlation\") & (data[\"Functional Similarity Measure\"] == \"Disagreement\")\n",
    "data.loc[idx, \"Setting\"] = \"disagr_corr\"\n",
    "\n",
    "data.loc[:, \"Representational Similarity Measure\"] = data[\"Representational Similarity Measure\"].map(\n",
    "    measure_to_abbrv\n",
    ")\n",
    "data.loc[:, \"architecture\"] = data[\"architecture\"].map(\n",
    "    {\n",
    "        \"BERT-L\": \"BERT\",\n",
    "        \"GCN\": \"GCN\",\n",
    "        \"GAT\": \"GAT\",\n",
    "        \"GraphSAGE\": \"SAGE\",\n",
    "        \"VGG11\": \"VGG11\",\n",
    "        \"VGG19\": \"VGG19\",\n",
    "        \"ResNet18\": \"RNet18\",\n",
    "        \"ResNet34\": \"RNet34\",\n",
    "        \"ResNet101\": \"RNet101\",\n",
    "        \"ViT_B32\": \"ViT_B32\",\n",
    "        \"ViT_L32\": \"ViT_L32\",\n",
    "        \"PGNN\": \"P-GNN\",\n",
    "    }\n",
    ")\n",
    "data.loc[:, \"domain\"] = data[\"domain\"].map({\"NLP\": \"Text\", \"GRAPHS\": \"Graph\", \"VISION\": \"Vision\"})\n",
    "data.loc[:, \"Dataset\"] = data[\"Dataset\"].map(\n",
    "    {\n",
    "        \"mnli_aug_rate0\": \"MNLI\",\n",
    "        \"mnli_mem_rate0\": \"MNLI\",\n",
    "        \"mnli\": \"MNLI\",\n",
    "        \"sst2_sc_rate0558\": \"SST2\",\n",
    "        \"sst2_mem_rate0\": \"SST2\",\n",
    "        \"mnli_sc_rate0354\": \"MNLI\",\n",
    "        \"sst2_aug_rate0\": \"SST2\",\n",
    "        \"sst2\": \"SST2\",\n",
    "        \"flickr\": \"flickr\",\n",
    "        \"ogbn-arxiv\": \"arXiv\",\n",
    "        \"cora\": \"Cora\",\n",
    "        \"in100\": \"IN100\",\n",
    "    }\n",
    ")\n",
    "data.loc[:, \"Setting\"] = data[\"Setting\"].map(\n",
    "    {\n",
    "        \"aug\": \"Augmentation\",\n",
    "        \"mem\": \"Random Labels\",\n",
    "        \"correlation\": \"JSD Corr.\",\n",
    "        \"acc_corr\": \"Acc Corr.\",\n",
    "        \"disagr_corr\": \"Disagr. Corr.\",\n",
    "        \"mono\": \"Layer Mono.\",\n",
    "        \"sc\": \"Shortcuts\",\n",
    "    }\n",
    ")\n",
    "column_order = [\"Acc Corr.\", \"Disagr. Corr.\", \"JSD Corr.\", \"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]\n",
    "data.loc[:, \"Setting\"] = pd.Categorical(\n",
    "    data[\"Setting\"],\n",
    "    categories=column_order,\n",
    "    ordered=True,\n",
    ")\n",
    "data.loc[:, \"Quality Measure\"] = data[\"Quality Measure\"].map(\n",
    "    {\"violation_rate\": \"Conformity Rate\", \"AUPRC\": \"AUPRC\", \"spearmanr\": \"Spearman\", \"correlation\": \"Spearman\"}\n",
    ")\n",
    "data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"] = (\n",
    "    1 - data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"]\n",
    ")  # must be run in conjunction with the above renaming\n",
    "\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"domain\": \"Modality\",\n",
    "        \"architecture\": \"Arch.\",\n",
    "        \"Representational Similarity Measure\": \"Sim Meas.\",\n",
    "        \"Quality Measure\": \"Eval.\",\n",
    "        \"Setting\": \"Test\",\n",
    "    }\n",
    ")\n",
    "data.loc[data.Test.isin([\"Acc Corr.\", \"Disagr. Corr.\", \"JSD Corr.\"]), \"Type\"] = \"Grounding by Prediction\"\n",
    "data.loc[data.Test.isin([\"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]), \"Type\"] = (\n",
    "    \"Grounding by Design\"\n",
    ")\n",
    "\n",
    "data = data[(~data[\"Eval.\"].isna()) & (data[\"Dataset\"] == \"Cora\") & (data[\"Test\"].isin([\"Acc Corr.\", \"Disagr. Corr.\", \"JSD Corr.\", \"Layer Mono.\"]))]\n",
    "\n",
    "pivot = pd.pivot_table(\n",
    "    data,\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=\"value\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=\"Sim Meas.\")\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Test\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "pivot = pivot.reindex([\"GAT\", \"GCN\", \"SAGE\", \"P-GNN\"], axis=\"columns\", level=\"Arch.\")\n",
    "pivot\n",
    "\n",
    "# turn vals into string\n",
    "unpivot = pivot.unstack().reset_index()  # values will be in col \"0\"\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].astype(\"str\")\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].apply(lambda x: f\"{round(x, 2):.2f}\")\n",
    "pivot = unpivot.pivot(index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=1,)\n",
    "unpivot\n",
    "\n",
    "\n",
    "for column in pivot.columns:\n",
    "    col = pivot.loc[:, column].astype(\"float\")\n",
    "    idx = col == col.max()\n",
    "    pivot.loc[idx, column] = pivot.loc[idx, column].apply(lambda s: r\"\\textbf{\" + s + \"}\")\n",
    "\n",
    "\n",
    "# add significance indicators\n",
    "idx = data[\"Dataset\"].isin([\"Cora\"]) & data.Test.isin([\"Acc Corr.\", \"Disagr. Corr.\", \"JSD Corr.\"])\n",
    "data_corr = data.loc[idx].copy()\n",
    "\n",
    "\n",
    "def pval_str(pval):\n",
    "    # if pval == pd.notna\n",
    "    if isinstance(pval, float):\n",
    "        if pval <= 0.01:\n",
    "            return r\"$^{**}$\"\n",
    "            # return r\"$^{\\dagger}$\"\n",
    "        if pval <= 0.05:\n",
    "            return r\"$^{*\\phantom{*}}$\"\n",
    "            # return r\"$^{\\ddagger}$\"\n",
    "    return r\"$^{\\phantom{**}}$\"\n",
    "\n",
    "data_corr[\"val_comb\"] = data_corr[\"value\"].apply(lambda x: f\"{round(x, ndigits=2):.2f}\") + data_corr[\"pval\"].apply(pval_str)\n",
    "data_corr\n",
    "\n",
    "pivot_corr = data_corr.drop_duplicates(\n",
    "    subset=[\n",
    "        \"Sim Meas.\",\n",
    "        \"Eval.\",\n",
    "        \"model\",\n",
    "        \"Modality\",\n",
    "        \"Arch.\",\n",
    "        \"representation_dataset\",\n",
    "        \"identifier\",\n",
    "        \"Test\",\n",
    "        \"Dataset\",\n",
    "        \"Functional Similarity Measure\",\n",
    "        \"Type\"\n",
    "        ]).pivot(\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=[\"val_comb\"],\n",
    ").sort_values(\n",
    "    by=\"Sim Meas.\"\n",
    ").reindex(\n",
    "    column_order, axis=\"columns\", level=\"Test\"\n",
    ").reindex(\n",
    "    [\"Graph\", \"Text\", \"Vision\"], axis=\"columns\", level=\"Modality\"\n",
    ").loc[:, \"val_comb\"]\n",
    "display(pivot_corr.head(3))\n",
    "\n",
    "\n",
    "def floatify(s: str) -> str:\n",
    "    \"\"\"Turn a string like '-0.10$^{\\phantom{**}}$' into '-0.10'\"\"\"\n",
    "    return s[:s.find(\"$\")]\n",
    "\n",
    "def separate_significance_indicator(s: str) -> str:\n",
    "    \"\"\"Turn a string like '-0.10$^{\\phantom{**}}$' into '$^{\\phantom{**}}$'\"\"\"\n",
    "    return s[s.find(\"$\"):]\n",
    "\n",
    "\n",
    "for column in pivot_corr.columns:\n",
    "    col = pivot_corr.loc[:, column].apply(floatify).astype(\"float\")\n",
    "    identifiers = pivot_corr.loc[:, column].apply(separate_significance_indicator)\n",
    "    idx = col == col.max()\n",
    "    new_col = col.apply(lambda x: f\"{x:.2f}\").apply(lambda s: r\"\\textbf{\" + s + \"}\") + identifiers\n",
    "    pivot_corr.loc[idx, column] = new_col\n",
    "\n",
    "\n",
    "pivot.loc[:, (\"Grounding by Prediction\")] = pivot_corr\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_corr), len(data_corr.drop_duplicates(subset=[\"Sim Meas.\", \"Eval.\", \"model\", \"Modality\", \"Arch.\", \"representation_dataset\", \"identifier\", \"Test\", \"Dataset\", \"Functional Similarity Measure\", \"Type\"]))\n",
    "# data_corr.drop_duplicates().groupby([\"Arch.\", \"Dataset\", \"Eval.\", \"Test\", \"Sim Meas.\"]).count()[(data_corr.drop_duplicates().groupby([\"Arch.\", \"Dataset\", \"Eval.\", \"Test\", \"Sim Meas.\"])[\"value\"].count() > 1)]\n",
    "\n",
    "# data_corr[(data_corr[\"Sim Meas.\"] == \"IMD\") & (data_corr[\"Dataset\"] == \"Cora\") & (data_corr[\"Arch.\"] == \"GAT\") & (data_corr[\"Test\"] == \"JSD Corr.\")]\n",
    "\n",
    "latex_str = pivot.to_latex()\n",
    "print(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Paper Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ranks = data.groupby([\"Scenario\",\"Sim Meas.\"])[\"rank\"].agg([\"mean\", \"median\"]).reset_index()\n",
    "avg_ranks = avg_ranks.rename(columns={\"mean\": \"avg_rank\", \"median\": \"med_rank\"})\n",
    "avg_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby([\"Scenario\",\"Sim Meas.\"])[\"rank\"].max().loc[\"JSD Corr.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ranks.pivot_table(values=\"avg_rank\", index=\"Sim Meas.\", columns=\"Scenario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ranks.to_csv(\"ranks_per_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.merge(data, avg_ranks).sort_values(by=[\"med_rank\"])\n",
    "g = sns.catplot(\n",
    "    data=plot_data,\n",
    "    x=\"med_rank\",\n",
    "    y=\"Sim Meas.\",\n",
    "    hue=\"Modality\",\n",
    "    kind=\"box\",\n",
    "    height=7,\n",
    "    aspect=0.8,\n",
    "    col=\"Scenario\",\n",
    "    palette={\"Language\": \"C1\", \"Vision\": \"C2\", \"Graph\": \"C0\"},\n",
    "    legend=False\n",
    ")\n",
    "ax = g.axes[0, 0]\n",
    "ax.set_xlabel(\"Rank\")\n",
    "ax.set_ylabel(\"Similarity Measures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
