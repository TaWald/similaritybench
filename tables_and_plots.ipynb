{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing and Plotting Results\n",
    "\n",
    "Contains two sections:\n",
    "1. How to create a summary table.\n",
    "2. How to create plots showing the ranks of the similarity measures.\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "This section of the notebook, creates the overview table in our paper. This code can be easily adjusted to also output more detailed tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.io.formats.style\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from repsim.benchmark.paths import BASE_PATH\n",
    "\n",
    "\n",
    "measure_to_abbrv = {\n",
    "    \"AlignedCosineSimilarity\": \"AlignCos\",\n",
    "    \"CKA\": \"CKA\",\n",
    "    \"ConcentricityDifference\": \"ConcDiff\",\n",
    "    \"DistanceCorrelation\": \"DistCorr\",\n",
    "    \"EigenspaceOverlapScore\": \"EOS\",\n",
    "    \"GeometryScore\": \"GS\",\n",
    "    \"Gulp\": \"GULP\",\n",
    "    \"HardCorrelationMatch\": \"HardCorr\",\n",
    "    \"IMDScore\": \"IMD\",\n",
    "    \"JaccardSimilarity\": \"Jaccard\",\n",
    "    \"LinearRegression\": \"LinReg\",\n",
    "    \"MagnitudeDifference\": \"MagDiff\",\n",
    "    \"OrthogonalAngularShapeMetricCentered\": \"AngShape\",\n",
    "    \"OrthogonalProcrustesCenteredAndNormalized\": \"OrthProc\",\n",
    "    \"PWCCA\": \"PWCCA\",\n",
    "    \"PermutationProcrustes\": \"PermProc\",\n",
    "    \"ProcrustesSizeAndShapeDistance\": \"ProcDist\",\n",
    "    \"RSA\": \"RSA\",\n",
    "    \"RSMNormDifference\": \"RSMDiff\",\n",
    "    \"RankSimilarity\": \"RankSim\",\n",
    "    \"SVCCA\": \"SVCCA\",\n",
    "    \"SecondOrderCosineSimilarity\": \"2nd-Cos\",\n",
    "    \"SoftCorrelationMatch\": \"SoftCorr\",\n",
    "    \"UniformityDifference\": \"UnifDiff\",\n",
    "    \"RTD\": \"RTD\",\n",
    "}\n",
    "\n",
    "measure_types = [\n",
    "    (\"AlignCos\", \"Alignment\"),\n",
    "    (\"HardCorr\", \"Alignment\"),\n",
    "    (\"AngShape\", \"Alignment\"),\n",
    "    (\"LinReg\", \"Alignment\"),\n",
    "    (\"OrthProc\", \"Alignment\"),\n",
    "    (\"PermProc\", \"Alignment\"),\n",
    "    (\"ProcDist\", \"Alignment\"),\n",
    "    (\"SoftCorr\", \"Alignment\"),\n",
    "\n",
    "    (\"EOS\", \"RSM\"),\n",
    "    (\"CKA\", \"RSM\"),\n",
    "    (\"DistCorr\", \"RSM\"),\n",
    "    (\"GULP\", \"RSM\"),\n",
    "    (\"RSA\", \"RSM\"),\n",
    "    (\"RSMDiff\", \"RSM\"),\n",
    "\n",
    "    (\"MagDiff\", \"Statistic\"),\n",
    "    (\"ConcDiff\", \"Statistic\"),\n",
    "    (\"UnifDiff\", \"Statistic\"),\n",
    "\n",
    "    (\"GS\", \"Topology\"),\n",
    "    (\"IMD\", \"Topology\"),\n",
    "    (\"RTD\", \"Topology\"),\n",
    "\n",
    "    (\"Jaccard\", \"Neighbors\"),\n",
    "    (\"RankSim\", \"Neighbors\"),\n",
    "    (\"2nd-Cos\", \"Neighbors\"),\n",
    "\n",
    "    (\"PWCCA\", \"CCA\"),\n",
    "    (\"SVCCA\", \"CCA\"),\n",
    "\n",
    "]\n",
    "\n",
    "measure_type_order = [\"CCA\", \"Alignment\", \"RSM\", \"Neighbors\", \"Topology\", \"Statistic\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "nlp_root = BASE_PATH /\"paper_results\" / \"nlp_iclr\"\n",
    "for path in nlp_root.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    setting = path.name.split(\"_\")[0]\n",
    "\n",
    "    pattern = r'(?<=_)sst2(?=_)|(?<=_)mnli(?=_)'\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    token = path.name.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    if \"smollm\" in path.name:\n",
    "        # not true, but we want to group standard non-aggregated token results for the llm with the cls token results for bert and albert\n",
    "        token = \"cls\"\n",
    "\n",
    "    df[\"Token\"] = token\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "nlp_data = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "root = BASE_PATH /\"paper_results\" /\"graph\"\n",
    "for path in root.glob(\"*.csv\"):\n",
    "    if path.name.endswith(\"backup.csv\"):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    pattern = r\"augmentation|label_test|layer_test|output_correlation|shortcut\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    pattern_to_setting = {\n",
    "        \"augmentation\": \"aug\",\n",
    "        \"label_test\": \"mem\",\n",
    "        \"layer_test\": \"mono\",\n",
    "        \"output_correlation\": \"correlation\",\n",
    "        \"shortcut\": \"sc\",\n",
    "    }\n",
    "    setting = pattern_to_setting[match.group(0)]\n",
    "\n",
    "    pattern = r\"(?<=_)cora(?=_)|(?<=_)flickr(?=_)|(?<=_)ogbn-arxiv(?=_)\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "graph_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "root = BASE_PATH /\"paper_results\" /\"vision_cameraready\"\n",
    "for path in root.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    pattern = r\"aug|augment|mem|randomlabel|mono|correlation|output|sc|shortcut\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    pattern_to_setting = {\n",
    "        \"aug\": \"aug\",\n",
    "        \"augment\": \"aug\",\n",
    "        \"mem\": \"mem\",\n",
    "        \"randomlabel\": \"mem\",\n",
    "        \"mono\": \"mono\",\n",
    "        \"correlation\": \"correlation\",\n",
    "        \"output\": \"correlation\",\n",
    "        \"sc\": \"sc\",\n",
    "        \"shortcut\": \"sc\",\n",
    "    }\n",
    "    setting = pattern_to_setting[match.group(0)]\n",
    "\n",
    "    pattern = r\"(?<=_)in100(?=_)|(?<=_)c100(?=_)|in100(?=_)|c100(?=_)|C100(?=_)\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None,  f\"{path} was not matched to setting\"\n",
    "    dataset = match.group(0)\n",
    "    if dataset == \"C100\":\n",
    "        dataset = \"c100\"\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "vision_data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Pivot\n",
    "\n",
    "Step 2: Combine data into a big dataframe, clean up column names etc., and select data to be shown in table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Combine data\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "data = pd.concat([nlp_data, graph_data, vision_data])\n",
    "print(data.columns)\n",
    "\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"functional_similarity_measure\": \"Functional Similarity Measure\",\n",
    "        \"similarity_measure\": \"Representational Similarity Measure\",\n",
    "        \"quality_measure\": \"Quality Measure\",\n",
    "    }\n",
    ")\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"value\"] = data.loc[idx, \"corr\"]\n",
    "\n",
    "idx = (data.Setting == \"correlation\") & (data[\"Functional Similarity Measure\"] == \"AbsoluteAccDiff\")\n",
    "data.loc[idx, \"Setting\"] = \"acc_corr\"\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Exclude data not to be shown in table.\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "idx = (data.Setting == \"correlation\") & (data[\"Functional Similarity Measure\"] != \"JSD\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "idx = (data.Setting.isin([\"aug\", \"mem\", \"sc\"])) & (data[\"Quality Measure\"] != \"AUPRC\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "idx = (data.Setting.isin([\"correlation\", \"acc_corr\"])) & (data[\"Quality Measure\"] != \"spearmanr\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "# idx = (data.Setting.isin([\"mono\"])) & (data[\"Quality Measure\"] != \"violation_rate\")\n",
    "idx = (data.Setting.isin([\"mono\"])) & (data[\"Quality Measure\"] != \"correlation\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "idx = (data.Token.isin([\"mean\"]))\n",
    "data = data.loc[~idx]\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Clean up names etc.\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def beautify_df(data):\n",
    "    data.loc[:, \"Representational Similarity Measure\"] = data[\"Representational Similarity Measure\"].map(\n",
    "        measure_to_abbrv\n",
    "    )\n",
    "    data.loc[:, \"architecture\"] = data[\"architecture\"].map(\n",
    "        {\n",
    "            \"smollm2-1.7b\": \"SmolLM2\",\n",
    "            \"albert-base-v2\": \"ALBERT\",\n",
    "            \"BERT-L\": \"BERT\",\n",
    "            \"GCN\": \"GCN\",\n",
    "            \"GAT\": \"GAT\",\n",
    "            \"GraphSAGE\": \"SAGE\",\n",
    "            \"VGG11\": \"VGG11\",\n",
    "            \"VGG19\": \"VGG19\",\n",
    "            \"ResNet18\": \"RNet18\",\n",
    "            \"ResNet34\": \"RNet34\",\n",
    "            \"ResNet101\": \"RNet101\",\n",
    "            \"ViT_B32\": \"ViT_B32\",\n",
    "            \"ViT_L32\": \"ViT_L32\",\n",
    "            \"PGNN\": \"P-GNN\",\n",
    "        }\n",
    "    )\n",
    "    data.loc[:, \"domain\"] = data[\"domain\"].map({\"NLP\": \"Text\", \"GRAPHS\": \"Graph\", \"VISION\": \"Vision\"})\n",
    "    data.loc[:, \"Dataset\"] = data[\"Dataset\"].map(\n",
    "        {\n",
    "            \"mnli_aug_rate0\": \"MNLI\",\n",
    "            \"mnli_mem_rate0\": \"MNLI\",\n",
    "            \"mnli\": \"MNLI\",\n",
    "            \"sst2_sc_rate0558\": \"SST2\",\n",
    "            \"sst2_mem_rate0\": \"SST2\",\n",
    "            \"sst2_sft\": \"SST2\",\n",
    "            \"sst2_sft_sc_rate0558\": \"SST2\",\n",
    "            \"mnli_sc_rate0354\": \"MNLI\",\n",
    "            \"sst2_aug_rate0\": \"SST2\",\n",
    "            \"sst2\": \"SST2\",\n",
    "            \"flickr\": \"flickr\",\n",
    "            \"ogbn-arxiv\": \"arXiv\",\n",
    "            \"cora\": \"Cora\",\n",
    "            \"in100\": \"IN100\",\n",
    "            \"c100\": \"CIFAR100\",\n",
    "        }\n",
    "    )\n",
    "    data.loc[:, \"Setting\"] = data[\"Setting\"].map(\n",
    "        {\n",
    "            \"aug\": \"Augmentation\",\n",
    "            \"mem\": \"Random Labels\",\n",
    "            \"correlation\": \"JSD Corr.\",\n",
    "            \"acc_corr\": \"Acc Corr.\",\n",
    "            \"mono\": \"Layer Mono.\",\n",
    "            \"sc\": \"Shortcuts\",\n",
    "        }\n",
    "    )\n",
    "    column_order = [\"Acc Corr.\", \"JSD Corr.\", \"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]\n",
    "    data.loc[:, \"Setting\"] = pd.Categorical(\n",
    "        data[\"Setting\"],\n",
    "        categories=column_order,\n",
    "        ordered=True,\n",
    "    )\n",
    "    data.loc[:, \"Quality Measure\"] = data[\"Quality Measure\"].map(\n",
    "        {\"violation_rate\": \"Conformity Rate\", \"AUPRC\": \"AUPRC\", \"spearmanr\": \"Spearman\", \"correlation\": \"Spearman\"}\n",
    "    )\n",
    "    data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"] = (\n",
    "        1 - data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"]\n",
    "    )  # must be run in conjunction with the above renaming\n",
    "\n",
    "    data = data.rename(\n",
    "        columns={\n",
    "            \"domain\": \"Domain\",\n",
    "            \"architecture\": \"Arch.\",\n",
    "            \"Representational Similarity Measure\": \"Sim Meas.\",\n",
    "            \"Quality Measure\": \"Eval.\",\n",
    "            \"Setting\": \"Test\",\n",
    "        }\n",
    "    )\n",
    "    data = pd.merge(data, pd.DataFrame.from_records(measure_types, columns=[\"Sim Meas.\", \"Measure Type\"]), how=\"left\", on=\"Sim Meas.\")\n",
    "    data.loc[:, \"Measure Type\"] = pd.Categorical(data[\"Measure Type\"], categories=measure_type_order, ordered=True)\n",
    "    data.loc[data.Test.isin([\"Acc Corr.\", \"JSD Corr.\"]), \"Type\"] = \"Grounding by Prediction\"\n",
    "    data.loc[data.Test.isin([\"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]), \"Type\"] = (\n",
    "        \"Grounding by Design\"\n",
    "    )\n",
    "    return data, column_order\n",
    "\n",
    "\n",
    "data, column_order = beautify_df(data)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Create aggregated overview table\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# idx = data[\"Dataset\"].isin([\"MNLI\", \"flickr\", \"IN100\"]) & data[\"Arch.\"].isin([\"SAGE\", \"BERT\", \"RNet18\"])\n",
    "idx = data[\"Dataset\"].isin([\"SST2\", \"flickr\", \"IN100\"]) & data[\"Arch.\"].isin([\"SAGE\", \"BERT\", \"RNet18\"])\n",
    "\n",
    "\n",
    "pivot = pd.pivot_table(\n",
    "    data.loc[idx],\n",
    "    index=[\"Measure Type\", \"Sim Meas.\"],  # <---\n",
    "    # index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Domain\", \"Dataset\", \"Arch.\"],\n",
    "    values=\"value\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=[\"Measure Type\", \"Sim Meas.\"], axis=\"index\")  # <---\n",
    "# pivot = pivot.sort_values(by=\"Sim Meas.\", axis=\"index\")\n",
    "pivot = pivot.reindex(measure_type_order, axis=\"index\", level=0)  # <---\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Test\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn values into strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpivot = pivot.unstack().unstack().dropna().reset_index()  # values will be in col \"0\"\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].astype(\"str\")\n",
    "unpivot.loc[:, 1] = unpivot.loc[:, 0].apply(lambda x: f\"{round(x, ndigits=2):.2f}\")\n",
    "pivot = unpivot.pivot(index=[\"Measure Type\", \"Sim Meas.\"],\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Domain\", \"Dataset\", \"Arch.\"],\n",
    "    values=1,)\n",
    "pivot = pivot.reindex(measure_type_order, axis=\"index\", level=0)  # <---\n",
    "\n",
    "unpivot\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight the best values by bolding\n",
    "for column in pivot.columns:\n",
    "    col = pivot.loc[:, column].astype(\"float\")\n",
    "    idx = col == col.max()\n",
    "    pivot.loc[idx, column] = pivot.loc[idx, column].apply(lambda s: r\"\\textbf{\" + s + \"}\")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = data[\"Dataset\"].isin([\"SST2\", \"flickr\", \"IN100\"]) & data[\"Arch.\"].isin([\"SAGE\", \"BERT\", \"RNet18\"]) & data.Test.isin([\"Acc Corr.\", \"JSD Corr.\"])\n",
    "# idx = data[\"Dataset\"].isin([\"MNLI\", \"flickr\", \"IN100\"]) & data[\"Arch.\"].isin([\"SAGE\", \"BERT\", \"RNet18\"]) & data.Test.isin([\"Acc Corr.\", \"JSD Corr.\"])\n",
    "data_corr = data.loc[idx].copy()\n",
    "\n",
    "\n",
    "def pval_str(pval):\n",
    "    # if pval == pd.notna\n",
    "    if isinstance(pval, float):\n",
    "        if pval <= 0.01:\n",
    "            return r\"$^{**}$\"\n",
    "            # return r\"$^{\\dagger}$\"\n",
    "        if pval <= 0.05:\n",
    "            return r\"$^{*\\phantom{*}}$\"\n",
    "            # return r\"$^{\\ddagger}$\"\n",
    "    return r\"$^{\\phantom{**}}$\"\n",
    "\n",
    "def significance_via_text_style(pval):\n",
    "    if pval <= 0.01:\n",
    "        return [r\"\\underline{\\underline{\", r\"}}\"]\n",
    "    if pval <= 0.05:\n",
    "        return [r\"\\underline{\", r\"}\"]\n",
    "    return [\"\", \"\"]\n",
    "\n",
    "data_corr[\"val_comb\"] = data_corr[\"value\"].apply(lambda x: f\"{round(x, ndigits=2):.2f}\") + data_corr[\"pval\"].apply(pval_str)\n",
    "# data_corr[\"val_comb\"] = data_corr[\"pval\"].apply(significance_via_text_style).apply(lambda x: x[0]) + data_corr[\"value\"].apply(lambda x: f\"{round(x, ndigits=2):.2f}\") + data_corr[\"pval\"].apply(significance_via_text_style).apply(lambda x: x[1])\n",
    "data_corr\n",
    "\n",
    "pivot_corr = data_corr.pivot(\n",
    "    index=[\"Measure Type\", \"Sim Meas.\"],\n",
    "    columns=[\"Type\", \"Test\", \"Eval.\", \"Domain\", \"Dataset\", \"Arch.\"],\n",
    "    values=[\"val_comb\"],\n",
    ").sort_values(\n",
    "    by=[\"Measure Type\", \"Sim Meas.\"],\n",
    ").reindex(\n",
    "    measure_type_order, axis=\"index\", level=0\n",
    ").reindex(\n",
    "    column_order, axis=\"columns\", level=\"Test\"\n",
    ").reindex(\n",
    "    [\"Graph\", \"Text\", \"Vision\"], axis=\"columns\", level=\"Domain\"\n",
    ").loc[:, \"val_comb\"]\n",
    "pivot_corr\n",
    "\n",
    "def floatify(s: str) -> str:\n",
    "    r\"\"\"Turn a string like '-0.10$^{\\phantom{**}}$' into '-0.10'\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    return s[:s.find(\"$\")]\n",
    "\n",
    "def separate_significance_indicator(s: str) -> str:\n",
    "    r\"\"\"Turn a string like '-0.10$^{\\phantom{**}}$' into '$^{\\phantom{**}}$'\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    return s[s.find(\"$\"):]\n",
    "\n",
    "for column in pivot_corr.columns:\n",
    "    col = pivot_corr.loc[:, column].apply(floatify).astype(\"float\")\n",
    "    identifiers = pivot_corr.loc[:, column].apply(separate_significance_indicator)\n",
    "    idx = col == col.max()\n",
    "    new_col = col.apply(lambda x: f\"{x:.2f}\").apply(lambda s: r\"\\textbf{\" + s + \"}\") + identifiers\n",
    "    pivot_corr.loc[idx, column] = new_col\n",
    "\n",
    "pivot_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot.loc[:, (\"Grounding by Prediction\")].astype(\"str\", copy=False)\n",
    "# pivot.loc[:, (\"Grounding by Prediction\", \"Acc Corr.\", \"Spearman\", \"Graph\", \"flickr\", \"SAGE\")] = pivot.loc[:, (\"Grounding by Prediction\", \"Acc Corr.\", \"Spearman\", \"Graph\", \"flickr\", \"SAGE\")].astype(\"str\")\n",
    "# pivot.loc[:, (\"Grounding by Prediction\")].dtypes\n",
    "\n",
    "pivot.loc[:, (\"Grounding by Prediction\")] = pivot_corr\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Convert into latex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled = pd.io.formats.style.Styler(\n",
    "    pivot,\n",
    "    precision=2,\n",
    ")\n",
    "\n",
    "# Highlight top value\n",
    "# latex_str = styled.highlight_max(axis=0, props=\"textbf:--rwrap;\").to_latex(\n",
    "#     hrules=True,\n",
    "#     position=\"t\",\n",
    "#     label=\"tab:result_overview\",\n",
    "# )\n",
    "latex_str = styled.to_latex(hrules=True, position=\"t\", label=\"tab:result_overview\",)\n",
    "\n",
    "\n",
    "# ----- Manual modifications --------\n",
    "latex_str = latex_str.split(\"\\n\")\n",
    "\n",
    "# Center headers\n",
    "pattern = r\"\\{r\\}\"\n",
    "replacement = r\"{c}\"\n",
    "latex_str = [re.sub(pattern, replacement, line) if i in [5, 6, 7] else line for i, line in enumerate(latex_str)]\n",
    "\n",
    "# Remove measure row\n",
    "latex_str.pop(11)\n",
    "\n",
    "# Add vertical bars\n",
    "line_no = 2\n",
    "# line_no = 3\n",
    "mod_line = latex_str[line_no][:18] + \"\".join([\"|rrr\"] * 6) + \"}\"\n",
    "latex_str[line_no] = mod_line\n",
    "\n",
    "# Make the left-most cells white\n",
    "latex_str = [\n",
    "    r\"\\cellcolor{white}\" + line if i >= 11 and (i - 11) % 2 == 0 else line for i, line in enumerate(latex_str[:-4])\n",
    "] + latex_str[-4:]\n",
    "latex_str = \"\\n\".join(latex_str)\n",
    "print(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rankplots\n",
    "\n",
    "Requires section above to be run as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(\"paper\", style=\"white\", font_scale=1.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine data similarly to before, but do not filter out specific parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([nlp_data, graph_data, vision_data])\n",
    "# display(data[(data.Setting == \"mono\") & (data.similarity_measure == \"RTD\")].head())\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"functional_similarity_measure\": \"Functional Similarity Measure\",\n",
    "        \"similarity_measure\": \"Representational Similarity Measure\",\n",
    "        \"quality_measure\": \"Quality Measure\",\n",
    "    }\n",
    ")\n",
    "data = data.reset_index()\n",
    "\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"value\"] = data.loc[idx, \"corr\"]\n",
    "\n",
    "idx = data[\"Quality Measure\"].isin([\"AUPRC\", \"spearmanr\", \"correlation\"])\n",
    "data = data.loc[idx]\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"Setting\"] = data.loc[idx, \"Setting\"] + data.loc[idx, \"Functional Similarity Measure\"]\n",
    "\n",
    "idx = ~(data.Setting == \"mono\")\n",
    "data.loc[idx, \"model\"] = \"agg\"\n",
    "\n",
    "idx = data.Token.isna()\n",
    "data.loc[idx, \"Token\"] = \"NA\"\n",
    "\n",
    "# idx = data.Token.isin([\"mean\"])\n",
    "# data = data.loc[~idx]\n",
    "\n",
    "data[\"rank\"] = data.groupby([\"domain\", \"Setting\", \"Dataset\", \"architecture\", \"model\", \"Token\"], as_index=True)[\"value\"].rank(\n",
    "    ascending=False, method=\"min\", na_option=\"keep\"\n",
    ")\n",
    "display(data[(data.Setting == \"mono\") & (data[\"Representational Similarity Measure\"] == \"RTD\")].head())\n",
    "\n",
    "\n",
    "# combine layer mono results to equally weight experiments\n",
    "idx = (data.model != \"agg\") & (~data[\"rank\"].isna())\n",
    "data.loc[idx, \"rank\"] = data[idx].groupby([\"domain\", \"Setting\", \"Dataset\", \"architecture\", \"Token\"])[\"rank\"].transform(\"mean\")\n",
    "data = data.drop_duplicates(subset=[\"domain\", \"Setting\", \"Dataset\", \"architecture\", \"Representational Similarity Measure\", \"Functional Similarity Measure\", \"Quality Measure\"])\n",
    "\n",
    "\n",
    "data.loc[:, \"Representational Similarity Measure\"] = data[\"Representational Similarity Measure\"].map(measure_to_abbrv)\n",
    "data.loc[:, \"architecture\"] = data[\"architecture\"].map(\n",
    "    {\n",
    "        \"smollm2-1.7b\": \"SmolLM2\",\n",
    "        \"albert-base-v2\": \"ALBERT\",\n",
    "        \"BERT-L\": \"BERT\",\n",
    "        \"GCN\": \"GCN\",\n",
    "        \"GAT\": \"GAT\",\n",
    "        \"GraphSAGE\": \"SAGE\",\n",
    "        \"VGG11\": \"VGG11\",\n",
    "        \"VGG19\": \"VGG19\",\n",
    "        \"ResNet18\": \"RNet18\",\n",
    "        \"ResNet34\": \"RNet34\",\n",
    "        \"ResNet101\": \"RNet101\",\n",
    "        \"ViT_B32\": \"ViT_B32\",\n",
    "        \"ViT_L32\": \"ViT_L32\",\n",
    "    }\n",
    ")\n",
    "data.loc[:, \"domain\"] = data[\"domain\"].map({\"NLP\": \"Language\", \"GRAPHS\": \"Graph\", \"VISION\": \"Vision\"})\n",
    "data.loc[:, \"Dataset\"] = data[\"Dataset\"].map(\n",
    "    {\n",
    "        \"mnli_aug_rate0\": \"MNLI\",\n",
    "        \"mnli_mem_rate0\": \"MNLI\",\n",
    "        \"mnli\": \"MNLI\",\n",
    "        \"sst2_sc_rate0558\": \"SST2\",\n",
    "        \"sst2_mem_rate0\": \"SST2\",\n",
    "        \"sst2_sft\": \"SST2\",\n",
    "        \"sst2_sft_sc_rate0558\": \"SST2\",\n",
    "        \"mnli_sc_rate0354\": \"MNLI\",\n",
    "        \"sst2_aug_rate0\": \"SST2\",\n",
    "        \"sst2\": \"SST2\",\n",
    "        \"flickr\": \"flickr\",\n",
    "        \"ogbn-arxiv\": \"arXiv\",\n",
    "        \"cora\": \"Cora\",\n",
    "        \"in100\": \"IN100\",\n",
    "        \"c100\": \"CIFAR100\",\n",
    "    }\n",
    ")\n",
    "data.loc[:, \"Setting\"] = data[\"Setting\"].map(\n",
    "    {\n",
    "        \"aug\": \"Augmentation\",\n",
    "        \"mem\": \"Random Labels\",\n",
    "        \"correlationJSD\": \"JSD Corr.\",\n",
    "        \"correlationAbsoluteAccDiff\": \"Acc Corr.\",\n",
    "        \"correlationDisagreement\": \"Disagr. Corr.\",\n",
    "        \"acc_corr\": \"Acc Corr.\",\n",
    "        \"mono\": \"Layer Mono.\",\n",
    "        \"sc\": \"Shortcuts\",\n",
    "    }\n",
    ")\n",
    "# display(data[(data.Setting == \"Layer Mono.\")  & (data[\"Representational Similarity Measure\"] == \"RTD\")].head())\n",
    "\n",
    "\n",
    "data.loc[:, \"Quality Measure\"] = data[\"Quality Measure\"].map(\n",
    "    {\"violation_rate\": \"Conformity Rate\", \"AUPRC\": \"AUPRC\", \"spearmanr\": \"Spearman\", \"correlation\": \"Spearman\"}\n",
    ")\n",
    "data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"] = (\n",
    "    1 - data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"]\n",
    ")  # must be run in conjunction with the above renaming\n",
    "# display(data[(data.Setting == \"Layer Mono.\") & (data[\"Representational Similarity Measure\"] == \"RTD\")].head())\n",
    "\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"domain\": \"Modality\",\n",
    "        \"architecture\": \"Arch.\",\n",
    "        \"Representational Similarity Measure\": \"Sim Meas.\",\n",
    "        \"Quality Measure\": \"Eval.\",\n",
    "        \"Setting\": \"Scenario\",\n",
    "    }\n",
    ")\n",
    "# display(data[(data.Scenario == \"Layer Mono.\") & (data[\"Sim Meas.\"] == \"RTD\")].head())\n",
    "\n",
    "data = data.sort_values(by=[\"Sim Meas.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.DataFrame({\"a\": [2, 2, 2, 2, 2, 2, 3]})\n",
    "fake.rank(method=\"min\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Rank measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ranks = data.groupby([\"Modality\", \"Sim Meas.\"])[\"rank\"].agg([\"mean\", \"median\"]).reset_index()\n",
    "avg_ranks = avg_ranks.rename(columns={\"mean\": \"avg_rank\", \"median\": \"med_rank\"})\n",
    "avg_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.merge(data, avg_ranks).sort_values(by=[\"med_rank\", \"avg_rank\"])\n",
    "plot_data = pd.merge(plot_data, pd.DataFrame.from_records(measure_types, columns=[\"Sim Meas.\", \"Measure Type\"]), how=\"left\", on=\"Sim Meas.\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, sharey=False, figsize=(7*0.8*3, 7))\n",
    "fig\n",
    "\n",
    "for i, mod in enumerate([\"Graph\", \"Language\", \"Vision\"]):\n",
    "    ax = axes[i]\n",
    "    sns.boxplot(\n",
    "        data=plot_data[plot_data.Modality == mod],\n",
    "        x=\"rank\",\n",
    "        y=\"Sim Meas.\",\n",
    "        hue=\"Measure Type\",\n",
    "        hue_order=[\"Neighbors\", \"RSM\", \"Alignment\", \"Topology\", \"CCA\", \"Statistic\"],\n",
    "        palette=\"colorblind\",\n",
    "        legend=True if mod==\"Vision\" else False,\n",
    "        ax=ax,\n",
    "        # whis=(5.,95.)\n",
    "    )\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    ax.set_xlabel(\"Rank\")\n",
    "    ax.set_ylabel(\"Similarity Measures\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if mod == \"Graph\":\n",
    "        ax.set_title(\"Graphs\")\n",
    "    else:\n",
    "        ax.set_title(mod)\n",
    "\n",
    "    if mod == \"Vision\":\n",
    "        sns.move_legend(ax, loc=\"right\", bbox_to_anchor=(1.45,0.5))\n",
    "    fig.savefig(BASE_PATH / \"figs\" / f\"aggregated_ver_{mod}.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
