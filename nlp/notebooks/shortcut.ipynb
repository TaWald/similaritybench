{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import transformers\n",
    "from bert_finetune import tokenize_function\n",
    "from omegaconf import OmegaConf\n",
    "from repsim.nlp import get_dataset, get_tokenizer, ShortcutAdder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_cfg(config_name):\n",
    "    return OmegaConf.load(f\"/root/similaritybench/nlp/config/dataset/{config_name}.yaml\")\n",
    "\n",
    "\n",
    "def get_model_cfg(config_name):\n",
    "    return OmegaConf.load(f\"/root/similaritybench/nlp/config/model/{config_name}.yaml\")\n",
    "\n",
    "\n",
    "def get_tokenizer(dataset_cfg, model_cfg):\n",
    "    return transformers.AutoTokenizer.from_pretrained(\n",
    "        model_cfg.kwargs.tokenizer_name,\n",
    "        additional_special_tokens=[f\"[CLASS{i}]\" for i in range(dataset_cfg.finetuning.num_labels)],\n",
    "    )\n",
    "\n",
    "\n",
    "def ratio_shortcut_equals_true_label(shortcut_strength, dataset, dataset_cfg, tokenizer, ratio_subset=\"validation\"):\n",
    "    dataset_name = dataset_cfg.path + \"__\" + dataset_cfg.name if dataset_cfg.name is not None else dataset_cfg.path\n",
    "    feature_column = dataset_cfg.feature_column[0]\n",
    "    sc_adder = ShortcutAdder(\n",
    "        num_labels=dataset_cfg.finetuning.num_labels, p=shortcut_strength, feature_column=feature_column\n",
    "    )\n",
    "    ds_w_shortcut = dataset.map(sc_adder)\n",
    "    tokenized_dataset = ds_w_shortcut.map(\n",
    "        partial(\n",
    "            tokenize_function,\n",
    "            tokenizer=tokenizer,\n",
    "            dataset_name=dataset_name,\n",
    "            feature_column=sc_adder.new_feature_column,\n",
    "        ),\n",
    "        batched=True,\n",
    "    )\n",
    "    additional_tokids_to_toks = {\n",
    "        idx: tok for tok, idx in zip(tokenizer.additional_special_tokens, tokenizer.additional_special_tokens_ids)\n",
    "    }\n",
    "\n",
    "    def shortcut_eq_label(example: dict[str, Any]) -> dict[str, str]:\n",
    "        label = example[\"label\"]\n",
    "        added_tok_id = example[\"input_ids\"][1]\n",
    "        shortcut_label = int(additional_tokids_to_toks[added_tok_id][6:-1])\n",
    "        # print(label, shortcut_label)\n",
    "        return {\"shortcut_eq_label\": label == shortcut_label}\n",
    "\n",
    "    new_ds = tokenized_dataset[ratio_subset].map(shortcut_eq_label)\n",
    "    return {\n",
    "        f\"ratio\": sum(new_ds[\"shortcut_eq_label\"]) / len(new_ds[\"shortcut_eq_label\"]),\n",
    "        \"dataset\": tokenized_dataset,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_class_distribution(dataset):\n",
    "    class_distributions = {}\n",
    "    for subset in dataset.keys():\n",
    "        labels_array = np.array(dataset[subset][\"label\"])\n",
    "\n",
    "        # Count the occurrences of each class using np.unique\n",
    "        unique_labels, label_counts = np.unique(labels_array, return_counts=True)\n",
    "\n",
    "        # Convert the results to a dict\n",
    "        class_distribution = dict(zip(unique_labels, label_counts))\n",
    "        class_distributions[subset] = class_distribution\n",
    "\n",
    "    return class_distributions\n",
    "\n",
    "\n",
    "def print_class_distributions(dataset):\n",
    "    class_distributions = get_class_distribution(dataset)\n",
    "    for subset, distribution in class_distributions.items():\n",
    "        print(f\"Class distribution for {subset}:\")\n",
    "        for label, count in distribution.items():\n",
    "            print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cfg = get_dataset_cfg(\"sst2\")\n",
    "model_cfg = get_model_cfg(\"multibert\")\n",
    "tokenizer = get_tokenizer(dataset_cfg, model_cfg)\n",
    "dataset = get_dataset(dataset_cfg.path, dataset_cfg.name)\n",
    "\n",
    "result = ratio_shortcut_equals_true_label(shortcut_strength=0.75, dataset, dataset_cfg, tokenizer)\n",
    "print(result[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = result[\"dataset\"]\n",
    "tokenized_dataset[\"validation\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cfg = get_dataset_cfg(\"mnli\")\n",
    "model_cfg = get_model_cfg(\"multibert\")\n",
    "tokenizer = get_tokenizer(dataset_cfg, model_cfg)\n",
    "dataset = get_dataset(dataset_cfg.path, dataset_cfg.name)\n",
    "\n",
    "result = ratio_shortcut_equals_true_label(0.25, dataset, dataset_cfg, tokenizer, \"validation_matched\")\n",
    "print(result[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_class_distributions(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrs = get_class_distribution(dataset)\n",
    "distr = distrs[\"validation_matched\"]\n",
    "[count / sum(distr.values()) for count in distr.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0.354, 1, num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
